// AI History Quiz - Level 7: Deep Learning Breakthrough (2010s)
(function() {
  const level7 = {
    name: {
      en: "AI History Level 7",
      es: "Historia de IA Nivel 7",
      de: "KI-Geschichte Stufe 7",
      nl: "AI Geschiedenis Level 7"
    },
    questions: [
      {
        question: {
          en: "What was the significance of AlexNet's victory in the 2012 ImageNet competition?",
          es: "¿Cuál fue la importancia de la victoria de AlexNet en la competencia ImageNet de 2012?",
          de: "Was war die Bedeutung von AlexNets Sieg im ImageNet-Wettbewerb 2012?",
          nl: "Wat was de betekenis van AlexNet's overwinning in de ImageNet competitie van 2012?"
        },
        options: [
          { en: "It sparked the modern deep learning revolution", es: "Desencadenó la revolución moderna del aprendizaje profundo", de: "Es löste die moderne Deep Learning-Revolution aus", nl: "Het veroorzaakte de moderne deep learning revolutie" },
          { en: "It was the first neural network ever created", es: "Fue la primera red neuronal jamás creada", de: "Es war das erste jemals erstellte neuronale Netzwerk", nl: "Het was het eerste neurale netwerk ooit gemaakt" },
          { en: "It solved natural language processing", es: "Resolvió el procesamiento de lenguaje natural", de: "Es löste die natürliche Sprachverarbeitung", nl: "Het loste natuurlijke taalverwerking op" },
          { en: "It created the first chatbot", es: "Creó el primer chatbot", de: "Es schuf den ersten Chatbot", nl: "Het creëerde de eerste chatbot" }
        ],
        correct: 0,
        explanation: {
          en: "AlexNet's dramatic victory by a large margin demonstrated the power of deep convolutional neural networks and GPU computing, triggering widespread adoption of deep learning across industries and research.",
          es: "La victoria dramática de AlexNet por un gran margen demostró el poder de las redes neuronales convolucionales profundas y la computación GPU, desencadenando la adopción generalizada del aprendizaje profundo en industrias e investigación.",
          de: "AlexNets dramatischer Sieg mit großem Vorsprung demonstrierte die Macht tiefer Convolutional Neural Networks und GPU-Computing und löste eine weitverbreitete Adoption von Deep Learning in Industrien und Forschung aus.",
          nl: "AlexNet's dramatische overwinning met een grote marge toonde de kracht van diepe convolutionele neurale netwerken en GPU computing, wat wijdverspreide adoptie van deep learning in industrieën en onderzoek veroorzaakte."
        }
      },
      {
        question: {
          en: "What was the significance of Geoffrey Hinton's work on deep belief networks in 2006?",
          es: "¿Cuál fue la importancia del trabajo de Geoffrey Hinton sobre redes de creencia profunda en 2006?",
          de: "Was war die Bedeutung von Geoffrey Hintons Arbeit an Deep Belief Networks 2006?",
          nl: "Wat was de betekenis van Geoffrey Hinton's werk aan deep belief networks in 2006?"
        },
        options: [
          { en: "It showed how to train deep neural networks effectively", es: "Mostró cómo entrenar redes neuronales profundas efectivamente", de: "Es zeigte wie man tiefe neuronale Netzwerke effektiv trainiert", nl: "Het toonde hoe diepe neurale netwerken effectief te trainen" },
          { en: "It created the first computer vision system", es: "Creó el primer sistema de visión por computadora", de: "Es schuf das erste Computer Vision-System", nl: "Het creëeerde het eerste computer vision systeem" },
          { en: "It solved the traveling salesman problem", es: "Resolvió el problema del vendedor viajero", de: "Es löste das Traveling Salesman-Problem", nl: "Het loste het handelsreizigersprobleem op" },
          { en: "It invented machine learning", es: "Inventó el aprendizaje automático", de: "Es erfand maschinelles Lernen", nl: "Het vond machine learning uit" }
        ],
        correct: 0,
        explanation: {
          en: "Hinton's 2006 paper on deep belief networks demonstrated effective layer-by-layer pre-training, overcoming the vanishing gradient problem and proving that deep neural networks could be trained successfully, launching the modern deep learning era.",
          es: "El artículo de Hinton de 2006 sobre redes de creencia profunda demostró pre-entrenamiento efectivo capa por capa, superando el problema del gradiente que desaparece y probando que las redes neuronales profundas podían entrenarse exitosamente, lanzando la era moderna del aprendizaje profundo.",
          de: "Hintons 2006 Arbeit über Deep Belief Networks demonstrierte effektives schichtweises Vortraining, überwand das Problem des verschwindenden Gradienten und bewies dass tiefe neuronale Netzwerke erfolgreich trainiert werden konnten, was die moderne Deep Learning-Ära einläutete.",
          nl: "Hinton's 2006 paper over deep belief networks toonde effectieve laag-voor-laag pre-training, overkomend het verdwijnende gradiënt probleem en bewees dat diepe neurale netwerken succesvol getraind konden worden, wat het moderne deep learning tijdperk inluidde."
        }
      },
      {
        question: {
          en: "What was the importance of the development of Word2Vec by Tomas Mikolov and colleagues in 2013?",
          es: "¿Cuál fue la importancia del desarrollo de Word2Vec por Tomas Mikolov y colegas en 2013?",
          de: "Was war die Wichtigkeit der Entwicklung von Word2Vec durch Tomas Mikolov und Kollegen 2013?",
          nl: "Wat was het belang van de ontwikkeling van Word2Vec door Tomas Mikolov en collega's in 2013?"
        },
        options: [
          { en: "It created vector representations of words that captured semantic relationships", es: "Creó representaciones vectoriales de palabras que capturaron relaciones semánticas", de: "Es schuf Vektordarstellungen von Wörtern die semantische Beziehungen erfassten", nl: "Het creëerde vectorrepresentaties van woorden die semantische relaties vastlegden" },
          { en: "It solved computer graphics", es: "Resolvió gráficos por computadora", de: "Es löste Computergrafik", nl: "Het loste computergraphics op" },
          { en: "It invented databases", es: "Inventó bases de datos", de: "Es erfand Datenbanken", nl: "Het vond databases uit" },
          { en: "It created operating systems", es: "Creó sistemas operativos", de: "Es schuf Betriebssysteme", nl: "Het creëerde besturingssystemen" }
        ],
        correct: 0,
        explanation: {
          en: "Word2Vec demonstrated that neural networks could learn dense vector representations of words that captured semantic and syntactic relationships, enabling operations like 'king - man + woman = queen' and revolutionizing natural language processing.",
          es: "Word2Vec demostró que las redes neuronales podían aprender representaciones vectoriales densas de palabras que capturaron relaciones semánticas y sintácticas, permitiendo operaciones como 'rey - hombre + mujer = reina' y revolucionando el procesamiento de lenguaje natural.",
          de: "Word2Vec demonstrierte dass neuronale Netzwerke dichte Vektordarstellungen von Wörtern lernen konnten die semantische und syntaktische Beziehungen erfassten, was Operationen wie 'König - Mann + Frau = Königin' ermöglichte und die natürliche Sprachverarbeitung revolutionierte.",
          nl: "Word2Vec toonde aan dat neurale netwerken dichte vectorrepresentaties van woorden konden leren die semantische en syntactische relaties vastlegden, waardoor operaties zoals 'koning - man + vrouw = koningin' mogelijk werden en natuurlijke taalverwerking revolutioneerden."
        }
      },
      {
        question: {
          en: "What was the significance of the development of Generative Adversarial Networks (GANs) by Ian Goodfellow in 2014?",
          es: "¿Cuál fue la importancia del desarrollo de Redes Adversarias Generativas (GAN) por Ian Goodfellow en 2014?",
          de: "Was war die Bedeutung der Entwicklung von Generative Adversarial Networks (GANs) durch Ian Goodfellow 2014?",
          nl: "Wat was de betekenis van de ontwikkeling van Generative Adversarial Networks (GANs) door Ian Goodfellow in 2014?"
        },
        options: [
          { en: "They revolutionized generative modeling by having two networks compete against each other", es: "Revolucionaron el modelado generativo haciendo que dos redes compitieran entre sí", de: "Sie revolutionierten generative Modellierung indem zwei Netzwerke gegeneinander konkurrierten", nl: "Ze revolutioneerden generatieve modellering door twee netwerken tegen elkaar te laten concurreren" },
          { en: "They solved natural language processing", es: "Resolvieron el procesamiento de lenguaje natural", de: "Sie lösten natürliche Sprachverarbeitung", nl: "Ze losten natuurlijke taalverwerking op" },
          { en: "They created the first neural network", es: "Crearon la primera red neuronal", de: "Sie schufen das erste neuronale Netzwerk", nl: "Ze creëerden het eerste neurale netwerk" },
          { en: "They invented reinforcement learning", es: "Inventaron el aprendizaje por refuerzo", de: "Sie erfanden Reinforcement Learning", nl: "Ze vonden reinforcement learning uit" }
        ],
        correct: 0,
        explanation: {
          en: "GANs introduced a novel training paradigm where a generator network creates fake data while a discriminator network tries to detect fakes, leading to remarkable advances in image generation, data augmentation, and creative AI applications.",
          es: "Los GAN introdujeron un paradigma de entrenamiento novedoso donde una red generadora crea datos falsos mientras una red discriminadora trata de detectar falsificaciones, llevando a avances notables en generación de imágenes, aumento de datos y aplicaciones de IA creativa.",
          de: "GANs führten ein neuartiges Trainingsparadigma ein bei dem ein Generator-Netzwerk falsche Daten erstellt während ein Diskriminator-Netzwerk versucht Fälschungen zu erkennen, was zu bemerkenswerten Fortschritten in Bildgenerierung, Datenaugmentierung und kreativen KI-Anwendungen führte.",
          nl: "GANs introduceerden een nieuw trainingsparadigma waarbij een generatornetwerk valse data creëert terwijl een discriminatornetwerk probeert vervalsingen te detecteren, leidend tot opmerkelijke vooruitgang in beeldgeneratie, data-augmentatie en creatieve AI toepassingen."
        }
      },
      {
        question: {
          en: "What was the significance of the development of Long Short-Term Memory (LSTM) networks by Hochreiter and Schmidhuber in 1997?",
          es: "¿Cuál fue la importancia del desarrollo de redes de Memoria a Largo y Corto Plazo (LSTM) por Hochreiter y Schmidhuber en 1997?",
          de: "Was war die Bedeutung der Entwicklung von Long Short-Term Memory (LSTM) Netzwerken durch Hochreiter und Schmidhuber 1997?",
          nl: "Wat was de betekenis van de ontwikkeling van Long Short-Term Memory (LSTM) netwerken door Hochreiter en Schmidhuber in 1997?"
        },
        options: [
          { en: "They solved the vanishing gradient problem in recurrent neural networks", es: "Resolvieron el problema del gradiente que desaparece en redes neuronales recurrentes", de: "Sie lösten das Problem des verschwindenden Gradienten in rekurrenten neuronalen Netzwerken", nl: "Ze losten het verdwijnende gradiënt probleem in recurrente neurale netwerken op" },
          { en: "They created the first computer", es: "Crearon la primera computadora", de: "Sie schufen den ersten Computer", nl: "Ze creëerden de eerste computer" },
          { en: "They invented programming languages", es: "Inventaron lenguajes de programación", de: "Sie erfanden Programmiersprachen", nl: "Ze vonden programmeertalen uit" },
          { en: "They solved database management", es: "Resolvieron gestión de bases de datos", de: "Sie lösten Datenbankmanagement", nl: "Ze losten database management op" }
        ],
        correct: 0,
        explanation: {
          en: "LSTM networks addressed the vanishing gradient problem that plagued traditional RNNs, enabling neural networks to learn long-term dependencies in sequential data. This breakthrough was crucial for advances in speech recognition, machine translation, and natural language processing.",
          es: "Las redes LSTM abordaron el problema del gradiente que desaparece que afectaba las RNN tradicionales, permitiendo a las redes neuronales aprender dependencias a largo plazo en datos secuenciales. Este avance fue crucial para avances en reconocimiento de voz, traducción automática y procesamiento de lenguaje natural.",
          de: "LSTM-Netzwerke lösten das Problem des verschwindenden Gradienten das traditionelle RNNs plagte, was neuronalen Netzwerken ermöglichte langfristige Abhängigkeiten in sequenziellen Daten zu lernen. Dieser Durchbruch war entscheidend für Fortschritte in Spracherkennung, maschineller Übersetzung und natürlicher Sprachverarbeitung.",
          nl: "LSTM netwerken pakten het verdwijnende gradiënt probleem aan dat traditionele RNNs plaagde, waardoor neurale netwerken lange termijn afhankelijkheden in sequentiële data konden leren. Deze doorbraak was cruciaal voor vooruitgang in spraakherkenning, machinevertaling en natuurlijke taalverwerking."
        }
      },
      {
        question: {
          en: "What was the impact of the development of VGGNet by the Visual Geometry Group at Oxford in 2014?",
          es: "¿Cuál fue el impacto del desarrollo de VGGNet por el Visual Geometry Group en Oxford en 2014?",
          de: "Was war die Auswirkung der Entwicklung von VGGNet durch die Visual Geometry Group in Oxford 2014?",
          nl: "Wat was de impact van de ontwikkeling van VGGNet door de Visual Geometry Group in Oxford in 2014?"
        },
        options: [
          { en: "It demonstrated that very deep networks with small filters could achieve excellent performance", es: "Demostró que redes muy profundas con filtros pequeños podían lograr excelente rendimiento", de: "Es demonstrierte dass sehr tiefe Netzwerke mit kleinen Filtern exzellente Leistung erreichen konnten", nl: "Het toonde aan dat zeer diepe netwerken met kleine filters uitstekende prestaties konden behalen" },
          { en: "It created the first web browser", es: "Creó el primer navegador web", de: "Es schuf den ersten Webbrowser", nl: "Het creëerde de eerste webbrowser" },
          { en: "It solved quantum mechanics", es: "Resolvió la mecánica cuántica", de: "Es löste die Quantenmechanik", nl: "Het loste quantummechanica op" },
          { en: "It invented machine translation", es: "Inventó la traducción automática", de: "Es erfand maschinelle Übersetzung", nl: "Het vond machinevertaling uit" }
        ],
        correct: 0,
        explanation: {
          en: "VGGNet showed that depth was crucial for good performance by using very small 3x3 convolutional filters stacked in deep architectures. It demonstrated that systematic increase in depth with small filters was more effective than using larger filters, influencing many subsequent architectures.",
          es: "VGGNet mostró que la profundidad era crucial para buen rendimiento usando filtros convolucionales muy pequeños de 3x3 apilados en arquitecturas profundas. Demostró que el aumento sistemático en profundidad con filtros pequeños era más efectivo que usar filtros más grandes, influyendo en muchas arquitecturas posteriores.",
          de: "VGGNet zeigte dass Tiefe entscheidend für gute Leistung war durch Verwendung sehr kleiner 3x3 Faltungsfilter gestapelt in tiefen Architekturen. Es demonstrierte dass systematische Zunahme der Tiefe mit kleinen Filtern effektiver war als größere Filter zu verwenden, was viele nachfolgende Architekturen beeinflusste.",
          nl: "VGGNet toonde aan dat diepte cruciaal was voor goede prestaties door zeer kleine 3x3 convolutie filters te gebruiken gestapeld in diepe architecturen. Het toonde aan dat systematische toename in diepte met kleine filters effectiever was dan het gebruik van grotere filters, wat veel volgende architecturen beïnvloedde."
        }
      },
      {
        question: {
          en: "What was the significance of the development of ResNet (Residual Networks) by Microsoft Research in 2015?",
          es: "¿Cuál fue la importancia del desarrollo de ResNet (Redes Residuales) por Microsoft Research en 2015?",
          de: "Was war die Bedeutung der Entwicklung von ResNet (Residual Networks) durch Microsoft Research 2015?",
          nl: "Wat was de betekenis van de ontwikkeling van ResNet (Residual Networks) door Microsoft Research in 2015?"
        },
        options: [
          { en: "It solved the degradation problem in very deep neural networks", es: "Resolvió el problema de degradación en redes neuronales muy profundas", de: "Es löste das Degradationsproblem in sehr tiefen neuronalen Netzwerken", nl: "Het loste het degradatieprobleem in zeer diepe neurale netwerken op" },
          { en: "It created the first AI system", es: "Creó el primer sistema de IA", de: "Es schuf das erste KI-System", nl: "Het creëerde het eerste AI systeem" },
          { en: "It invented machine learning", es: "Inventó el aprendizaje automático", de: "Es erfand maschinelles Lernen", nl: "Het vond machine learning uit" },
          { en: "It solved speech recognition", es: "Resolvió el reconocimiento de voz", de: "Es löste Spracherkennung", nl: "Het loste spraakherkenning op" }
        ],
        correct: 0,
        explanation: {
          en: "ResNet introduced skip connections that allowed gradients to flow directly to earlier layers, solving the degradation problem where deeper networks performed worse than shallow ones, enabling the training of networks with hundreds of layers.",
          es: "ResNet introdujo conexiones de salto que permitieron a los gradientes fluir directamente a capas anteriores, resolviendo el problema de degradación donde redes más profundas tuvieron peor rendimiento que las superficiales, permitiendo entrenar redes con cientos de capas.",
          de: "ResNet führte Skip-Verbindungen ein die Gradienten erlaubten direkt zu früheren Schichten zu fließen, löste das Degradationsproblem bei dem tiefere Netzwerke schlechter abschnitten als flache, und ermöglichte das Training von Netzwerken mit Hunderten von Schichten.",
          nl: "ResNet introduceerde skip-verbindingen die gradiënten toestonden direct naar eerdere lagen te stromen, het degradatieprobleem oplossend waarbij diepere netwerken slechter presteerden dan ondiepe, waardoor training van netwerken met honderden lagen mogelijk werd."
        }
      },
      {
        question: {
          en: "What was the contribution of Yoshua Bengio's work on attention mechanisms in neural networks?",
          es: "¿Cuál fue la contribución del trabajo de Yoshua Bengio sobre mecanismos de atención en redes neuronales?",
          de: "Was war der Beitrag von Yoshua Bengios Arbeit über Aufmerksamkeitsmechanismen in neuronalen Netzwerken?",
          nl: "Wat was de bijdrage van Yoshua Bengio's werk aan aandachtsmechanismen in neurale netwerken?"
        },
        options: [
          { en: "He enabled neural networks to focus on relevant parts of input sequences", es: "Permitió a las redes neuronales enfocarse en partes relevantes de secuencias de entrada", de: "Er ermöglichte neuronalen Netzwerken sich auf relevante Teile von Eingabesequenzen zu konzentrieren", nl: "Hij stelde neurale netwerken in staat om te focussen op relevante delen van invoersequenties" },
          { en: "He created the first computer", es: "Creó la primera computadora", de: "Er schuf den ersten Computer", nl: "Hij creëerde de eerste computer" },
          { en: "He invented the internet", es: "Inventó internet", de: "Er erfand das Internet", nl: "Hij vond het internet uit" },
          { en: "He solved quantum computing", es: "Resolvió la computación cuántica", de: "Er löste Quantencomputing", nl: "Hij loste quantum computing op" }
        ],
        correct: 0,
        explanation: {
          en: "Bengio's work on attention mechanisms, particularly in the context of neural machine translation, allowed networks to selectively focus on different parts of input sequences, dramatically improving performance and laying groundwork for the Transformer architecture.",
          es: "El trabajo de Bengio sobre mecanismos de atención, particularmente en el contexto de traducción automática neuronal, permitió a las redes enfocarse selectivamente en diferentes partes de secuencias de entrada, mejorando dramáticamente el rendimiento y sentando las bases para la arquitectura Transformer.",
          de: "Bengios Arbeit über Aufmerksamkeitsmechanismen, besonders im Kontext neuronaler maschineller Übersetzung, erlaubte Netzwerken sich selektiv auf verschiedene Teile von Eingabesequenzen zu konzentrieren, was die Leistung dramatisch verbesserte und den Grundstein für die Transformer-Architektur legte.",
          nl: "Bengio's werk aan aandachtsmechanismen, vooral in de context van neurale machinevertaling, stelde netwerken in staat om selectief te focussen op verschillende delen van invoersequenties, wat de prestaties dramatisch verbeterde en de basis legde voor de Transformer architectuur."
        }
      },
      {
        question: {
          en: "What was the impact of the introduction of batch normalization by Ioffe and Szegedy in 2015?",
          es: "¿Cuál fue el impacto de la introducción de normalización por lotes por Ioffe y Szegedy en 2015?",
          de: "Was war die Auswirkung der Einführung von Batch-Normalisierung durch Ioffe und Szegedy 2015?",
          nl: "Wat was de impact van de introductie van batch normalization door Ioffe en Szegedy in 2015?"
        },
        options: [
          { en: "It significantly accelerated deep network training and improved stability", es: "Aceleró significativamente el entrenamiento de redes profundas y mejoró la estabilidad", de: "Es beschleunigte das Training tiefer Netzwerke erheblich und verbesserte die Stabilität", nl: "Het versnelde aanzienlijk het trainen van diepe netwerken en verbeterde de stabiliteit" },
          { en: "It created the first neural network", es: "Creó la primera red neuronal", de: "Es schuf das erste neuronale Netzwerk", nl: "Het creëerde het eerste neurale netwerk" },
          { en: "It solved the halting problem", es: "Resolvió el problema de la parada", de: "Es löste das Halteproblem", nl: "Het loste het halting probleem op" },
          { en: "It invented parallel computing", es: "Inventó la computación paralela", de: "Es erfand paralleles Computing", nl: "Het vond parallel computing uit" }
        ],
        correct: 0,
        explanation: {
          en: "Batch normalization normalized the inputs to each layer, reducing internal covariate shift and allowing for higher learning rates, faster convergence, and more stable training of deep neural networks. It became a standard component in most modern architectures.",
          es: "La normalización por lotes normalizó las entradas a cada capa, reduciendo el cambio de covariable interno y permitiendo tasas de aprendizaje más altas, convergencia más rápida y entrenamiento más estable de redes neuronales profundas. Se convirtió en un componente estándar en la mayoría de arquitecturas modernas.",
          de: "Batch-Normalisierung normalisierte die Eingaben zu jeder Schicht, reduzierte interne Kovariatenverschiebung und ermöglichte höhere Lernraten, schnellere Konvergenz und stabileres Training tiefer neuronaler Netzwerke. Es wurde zu einer Standardkomponente in den meisten modernen Architekturen.",
          nl: "Batch normalization normaliseerde de inputs naar elke laag, verminderde interne covariate shift en maakte hogere leersnelheden, snellere convergentie en stabielere training van diepe neurale netwerken mogelijk. Het werd een standaardcomponent in de meeste moderne architecturen."
        }
      },
      {
        question: {
          en: "What was the significance of the GoogLeNet/Inception architecture developed by Google in 2014?",
          es: "¿Cuál fue la importancia de la arquitectura GoogLeNet/Inception desarrollada por Google en 2014?",
          de: "Was war die Bedeutung der GoogLeNet/Inception-Architektur entwickelt von Google 2014?",
          nl: "Wat was de betekenis van de GoogLeNet/Inception architectuur ontwikkeld door Google in 2014?"
        },
        options: [
          { en: "It introduced the concept of inception modules with multi-scale feature extraction", es: "Introdujo el concepto de módulos inception con extracción de características multi-escala", de: "Es führte das Konzept von Inception-Modulen mit multi-skaliger Feature-Extraktion ein", nl: "Het introduceerde het concept van inception modules met multi-schaal feature extractie" },
          { en: "It created the first search engine", es: "Creó el primer motor de búsqueda", de: "Es schuf die erste Suchmaschine", nl: "Het creëerde de eerste zoekmachine" },
          { en: "It solved natural language processing", es: "Resolvió el procesamiento de lenguaje natural", de: "Es löste natürliche Sprachverarbeitung", nl: "Het loste natuurlijke taalverwerking op" },
          { en: "It invented mobile computing", es: "Inventó la computación móvil", de: "Es erfand mobiles Computing", nl: "Het vond mobiele computing uit" }
        ],
        correct: 0,
        explanation: {
          en: "GoogLeNet introduced inception modules that applied multiple convolutional filters of different sizes in parallel, allowing the network to capture features at multiple scales efficiently. This innovation reduced parameters while maintaining performance and influenced many subsequent architectures.",
          es: "GoogLeNet introdujo módulos inception que aplicaron múltiples filtros convolucionales de diferentes tamaños en paralelo, permitiendo a la red capturar características en múltiples escalas eficientemente. Esta innovación redujo parámetros mientras mantuvo rendimiento e influyó en muchas arquitecturas posteriores.",
          de: "GoogLeNet führte Inception-Module ein die multiple Faltungsfilter verschiedener Größen parallel anwendeten, was dem Netzwerk erlaubte Features auf mehreren Skalen effizient zu erfassen. Diese Innovation reduzierte Parameter während die Leistung beibehalten wurde und beeinflusste viele nachfolgende Architekturen.",
          nl: "GoogLeNet introduceerde inception modules die meerdere convolutionele filters van verschillende groottes parallel toepasten, waardoor het netwerk features op meerdere schalen efficiënt kon vastleggen. Deze innovatie verminderde parameters terwijl prestaties behouden bleven en beïnvloedde veel volgende architecturen."
        }
      },
      {
        question: {
          en: "What was the role of GPU computing in enabling the deep learning revolution of the 2010s?",
          es: "¿Cuál fue el papel de la computación GPU en permitir la revolución del aprendizaje profundo de los años 2010?",
          de: "Was war die Rolle von GPU-Computing beim Ermöglichen der Deep Learning-Revolution der 2010er?",
          nl: "Wat was de rol van GPU computing in het mogelijk maken van de deep learning revolutie van de jaren 2010?"
        },
        options: [
          { en: "GPUs provided the massive parallel processing power needed to train large neural networks efficiently", es: "Los GPU proporcionaron el poder de procesamiento paralelo masivo necesario para entrenar grandes redes neuronales eficientemente", de: "GPUs boten die massive parallele Verarbeitungsleistung die benötigt wurde um große neuronale Netzwerke effizient zu trainieren", nl: "GPU's boden de massieve parallelle verwerkingskracht die nodig was om grote neurale netwerken efficiënt te trainen" },
          { en: "GPUs made computers cheaper", es: "Los GPU hicieron las computadoras más baratas", de: "GPUs machten Computer billiger", nl: "GPU's maakten computers goedkoper" },
          { en: "GPUs invented the internet", es: "Los GPU inventaron internet", de: "GPUs erfanden das Internet", nl: "GPU's vonden het internet uit" },
          { en: "GPUs solved all programming problems", es: "Los GPU resolvieron todos los problemas de programación", de: "GPUs lösten alle Programmierproblem", nl: "GPU's losten alle programmeerproblemen op" }
        ],
        correct: 0,
        explanation: {
          en: "GPUs' highly parallel architecture was ideal for the matrix operations in neural network training. NVIDIA's CUDA programming model and later frameworks like cuDNN made deep learning accessible, reducing training times from months to days and enabling the practical training of large models.",
          es: "La arquitectura altamente paralela de los GPU era ideal para las operaciones matriciales en entrenamiento de redes neuronales. El modelo de programación CUDA de NVIDIA y marcos posteriores como cuDNN hicieron accesible el aprendizaje profundo, reduciendo tiempos de entrenamiento de meses a días y permitiendo entrenamiento práctico de modelos grandes.",
          de: "GPUs hochparallele Architektur war ideal für die Matrixoperationen im neuronalen Netzwerk-Training. NVIDIAs CUDA-Programmiermodell und spätere Frameworks wie cuDNN machten Deep Learning zugänglich, reduzierten Trainingszeiten von Monaten auf Tage und ermöglichten praktisches Training großer Modelle.",
          nl: "GPU's zeer parallelle architectuur was ideaal voor de matrixoperaties in neurale netwerk training. NVIDIA's CUDA programmeermodel en latere frameworks zoals cuDNN maakten deep learning toegankelijk, verminderden trainingstijden van maanden naar dagen en maakten praktische training van grote modellen mogelijk."
        }
      },
      {
        question: {
          en: "What was the significance of the development of GloVe (Global Vectors) by Pennington et al. in 2014?",
          es: "¿Cuál fue la importancia del desarrollo de GloVe (Vectores Globales) por Pennington et al. en 2014?",
          de: "Was war die Bedeutung der Entwicklung von GloVe (Global Vectors) durch Pennington et al. 2014?",
          nl: "Wat was de betekenis van de ontwikkeling van GloVe (Global Vectors) door Pennington et al. in 2014?"
        },
        options: [
          { en: "It combined the advantages of matrix factorization and local context window methods for word embeddings", es: "Combinó las ventajas de factorización de matrices y métodos de ventana de contexto local para embeddings de palabras", de: "Es kombinierte die Vorteile von Matrixfaktorisierung und lokalen Kontextfenster-Methoden für Wort-Embeddings", nl: "Het combineerde de voordelen van matrixfactorisatie en lokale context venster methoden voor woord embeddings" },
          { en: "It created the first operating system", es: "Creó el primer sistema operativo", de: "Es schuf das erste Betriebssystem", nl: "Het creëerde het eerste besturingssysteem" },
          { en: "It solved quantum computing", es: "Resolvió la computación cuántica", de: "Es löste Quantencomputing", nl: "Het loste quantum computing op" },
          { en: "It invented virtual reality", es: "Inventó la realidad virtual", de: "Es erfand virtuelle Realität", nl: "Het vond virtual reality uit" }
        ],
        correct: 0,
        explanation: {
          en: "GloVe bridged the gap between count-based methods (like LSA) and prediction-based methods (like Word2Vec) by leveraging global statistical information while maintaining the semantic relationships. It became widely adopted for generating high-quality word embeddings.",
          es: "GloVe cerró la brecha entre métodos basados en conteo (como LSA) y métodos basados en predicción (como Word2Vec) aprovechando información estadística global mientras mantenía las relaciones semánticas. Se adoptó ampliamente para generar embeddings de palabras de alta calidad.",
          de: "GloVe überbrückte die Lücke zwischen zählbasierten Methoden (wie LSA) und vorhersagebasierten Methoden (wie Word2Vec) durch Nutzung globaler statistischer Informationen während semantische Beziehungen beibehalten wurden. Es wurde weit verbreitet zur Generierung hochwertiger Wort-Embeddings angenommen.",
          nl: "GloVe overbrugde de kloof tussen tel-gebaseerde methoden (zoals LSA) en voorspelling-gebaseerde methoden (zoals Word2Vec) door globale statistische informatie te benutten terwijl semantische relaties behouden bleven. Het werd breed aangenomen voor het genereren van hoogwaardige woord embeddings."
        }
      },
      {
        question: {
          en: "What was the impact of the development of Seq2Seq (Sequence-to-Sequence) models by Sutskever et al. in 2014?",
          es: "¿Cuál fue el impacto del desarrollo de modelos Seq2Seq (Secuencia-a-Secuencia) por Sutskever et al. en 2014?",
          de: "Was war die Auswirkung der Entwicklung von Seq2Seq (Sequence-to-Sequence) Modellen durch Sutskever et al. 2014?",
          nl: "Wat was de impact van de ontwikkeling van Seq2Seq (Sequence-to-Sequence) modellen door Sutskever et al. in 2014?"
        },
        options: [
          { en: "They enabled neural networks to handle variable-length input and output sequences for tasks like translation", es: "Permitieron a las redes neuronales manejar secuencias de entrada y salida de longitud variable para tareas como traducción", de: "Sie ermöglichten neuronalen Netzwerken variable Eingabe- und Ausgabesequenzen für Aufgaben wie Übersetzung zu handhaben", nl: "Ze stelden neurale netwerken in staat om variabele-lengte invoer en uitvoer sequenties te behandelen voor taken zoals vertaling" },
          { en: "They created the first database", es: "Crearon la primera base de datos", de: "Sie schufen die erste Datenbank", nl: "Ze creëerden de eerste database" },
          { en: "They solved image recognition", es: "Resolvieron el reconocimiento de imágenes", de: "Sie lösten Bilderkennung", nl: "Ze losten beeldherkenning op" },
          { en: "They invented social media", es: "Inventaron las redes sociales", de: "Sie erfanden soziale Medien", nl: "Ze vonden sociale media uit" }
        ],
        correct: 0,
        explanation: {
          en: "Seq2Seq models used an encoder-decoder architecture with LSTMs to map variable-length input sequences to variable-length output sequences. This approach revolutionized machine translation, text summarization, and dialogue systems, paving the way for more sophisticated sequence modeling.",
          es: "Los modelos Seq2Seq usaron una arquitectura codificador-decodificador con LSTM para mapear secuencias de entrada de longitud variable a secuencias de salida de longitud variable. Este enfoque revolucionó la traducción automática, resumen de texto y sistemas de diálogo, allanando el camino para modelado de secuencias más sofisticado.",
          de: "Seq2Seq-Modelle verwendeten eine Encoder-Decoder-Architektur mit LSTMs um variable Eingabesequenzen auf variable Ausgabesequenzen zu mappen. Dieser Ansatz revolutionierte maschinelle Übersetzung, Textzusammenfassung und Dialogsysteme und ebnete den Weg für anspruchsvollere Sequenzmodellierung.",
          nl: "Seq2Seq modellen gebruikten een encoder-decoder architectuur met LSTMs om variabele-lengte invoersequenties naar variabele-lengte uitvoersequenties te mappen. Deze benadering revolutioneerde machinevertaling, tekstsamenvatting en dialoogsystemen, waarmee de weg werd geëffend voor geavanceerdere sequentiemodellering."
        }
      },
      {
        question: {
          en: "What was the significance of dropout regularization introduced by Hinton et al. in 2012?",
          es: "¿Cuál fue la importancia de la regularización dropout introducida por Hinton et al. en 2012?",
          de: "Was war die Bedeutung der Dropout-Regularisierung eingeführt von Hinton et al. 2012?",
          nl: "Wat was de betekenis van dropout regularisatie geïntroduceerd door Hinton et al. in 2012?"
        },
        options: [
          { en: "It provided an effective way to prevent overfitting in deep neural networks", es: "Proporcionó una forma efectiva de prevenir sobreajuste en redes neuronales profundas", de: "Es bot eine effektive Weise Overfitting in tiefen neuronalen Netzwerken zu verhindern", nl: "Het bood een effectieve manier om overfitting in diepe neurale netwerken te voorkomen" },
          { en: "It made computers faster", es: "Hizo las computadoras más rápidas", de: "Es machte Computer schneller", nl: "Het maakte computers sneller" },
          { en: "It created artificial consciousness", es: "Creó conciencia artificial", de: "Es schuf künstliches Bewusstsein", nl: "Het creëerde kunstmatig bewustzijn" },
          { en: "It solved the energy crisis", es: "Resolvió la crisis energética", de: "Es löste die Energiekrise", nl: "Het loste de energiecrisis op" }
        ],
        correct: 0,
        explanation: {
          en: "Dropout randomly sets some neurons to zero during training, forcing the network to not rely on any single neuron. This simple but effective technique dramatically reduced overfitting in deep networks and became a standard regularization method in the deep learning toolkit.",
          es: "Dropout establece aleatoriamente algunas neuronas en cero durante el entrenamiento, forzando a la red a no depender de ninguna neurona individual. Esta técnica simple pero efectiva redujo dramáticamente el sobreajuste en redes profundas y se convirtió en un método estándar de regularización en el kit de herramientas de aprendizaje profundo.",
          de: "Dropout setzt zufällig einige Neuronen während des Trainings auf null, was das Netzwerk zwingt nicht auf einzelne Neuronen angewiesen zu sein. Diese einfache aber effektive Technik reduzierte Overfitting in tiefen Netzwerken dramatisch und wurde zu einer Standard-Regularisierungsmethode im Deep Learning-Toolkit.",
          nl: "Dropout zet willekeurig enkele neuronen op nul tijdens training, waardoor het netwerk wordt gedwongen niet te vertrouwen op een enkele neuron. Deze eenvoudige maar effectieve techniek verminderde overfitting in diepe netwerken dramatisch en werd een standaard regularisatiemethode in de deep learning toolkit."
        }
      },
      {
        question: {
          en: "What was the impact of the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) on deep learning development?",
          es: "¿Cuál fue el impacto del Desafío de Reconocimiento Visual a Gran Escala ImageNet (ILSVRC) en el desarrollo del aprendizaje profundo?",
          de: "Was war die Auswirkung der ImageNet Large Scale Visual Recognition Challenge (ILSVRC) auf die Deep Learning-Entwicklung?",
          nl: "Wat was de impact van de ImageNet Large Scale Visual Recognition Challenge (ILSVRC) op deep learning ontwikkeling?"
        },
        options: [
          { en: "It provided a standardized benchmark that drove innovation and competition in computer vision", es: "Proporcionó una referencia estandarizada que impulsó innovación y competencia en visión por computadora", de: "Es bot eine standardisierte Benchmark die Innovation und Wettbewerb in Computer Vision antrieb", nl: "Het bood een gestandaardiseerde benchmark die innovatie en competitie in computer vision aandreef" },
          { en: "It created the first computer", es: "Creó la primera computadora", de: "Es schuf den ersten Computer", nl: "Het creëerde de eerste computer" },
          { en: "It solved natural language processing", es: "Resolvió el procesamiento de lenguaje natural", de: "Es löste natürliche Sprachverarbeitung", nl: "Het loste natuurlijke taalverwerking op" },
          { en: "It invented the internet", es: "Inventó internet", de: "Es erfand das Internet", nl: "Het vond het internet uit" }
        ],
        correct: 0,
        explanation: {
          en: "ILSVRC became the premier computer vision competition with millions of labeled images across thousands of categories. It provided a rigorous testing ground that motivated algorithmic innovations, with AlexNet's 2012 victory marking the beginning of the deep learning era in computer vision.",
          es: "ILSVRC se convirtió en la competencia premier de visión por computadora con millones de imágenes etiquetadas en miles de categorías. Proporcionó un terreno de prueba riguroso que motivó innovaciones algorítmicas, con la victoria de AlexNet en 2012 marcando el comienzo de la era del aprendizaje profundo en visión por computadora.",
          de: "ILSVRC wurde zur führenden Computer Vision-Konkurrenz mit Millionen beschrifteter Bilder in Tausenden von Kategorien. Es bot ein rigoroses Testfeld das algorithmische Innovationen motivierte, wobei AlexNets Sieg 2012 den Beginn der Deep Learning-Ära in Computer Vision markierte.",
          nl: "ILSVRC werd de belangrijkste computer vision competitie met miljoenen gelabelde afbeeldingen in duizenden categorieën. Het bood een rigoureus testterrein dat algoritmische innovaties motiveerde, waarbij AlexNet's overwinning in 2012 het begin van het deep learning tijdperk in computer vision markeerde."
        }
      },
      {
        question: {
          en: "What was the significance of the development of DenseNet by Huang et al. in 2016?",
          es: "¿Cuál fue la importancia del desarrollo de DenseNet por Huang et al. en 2016?",
          de: "Was war die Bedeutung der Entwicklung von DenseNet durch Huang et al. 2016?",
          nl: "Wat was de betekenis van de ontwikkeling van DenseNet door Huang et al. in 2016?"
        },
        options: [
          { en: "It introduced dense connections where each layer connects to every subsequent layer", es: "Introdujo conexiones densas donde cada capa se conecta a cada capa subsecuente", de: "Es führte dichte Verbindungen ein bei denen jede Schicht sich mit jeder nachfolgenden Schicht verbindet", nl: "Het introduceerde dichte verbindingen waarbij elke laag verbindt met elke volgende laag" },
          { en: "It created the first mobile phone", es: "Creó el primer teléfono móvil", de: "Es schuf das erste Mobiltelefon", nl: "Het creëerde de eerste mobiele telefoon" },
          { en: "It solved quantum mechanics", es: "Resolvió la mecánica cuántica", de: "Es löste die Quantenmechanik", nl: "Het loste quantummechanica op" },
          { en: "It invented blockchain technology", es: "Inventó la tecnología blockchain", de: "Es erfand Blockchain-Technologie", nl: "Het vond blockchain technologie uit" }
        ],
        correct: 0,
        explanation: {
          en: "DenseNet connected each layer to every subsequent layer in a feed-forward fashion, creating extremely dense connectivity. This design improved gradient flow, reduced parameters through feature reuse, and achieved excellent performance with fewer parameters than traditional architectures.",
          es: "DenseNet conectó cada capa a cada capa subsecuente de manera feed-forward, creando conectividad extremadamente densa. Este diseño mejoró el flujo de gradientes, redujo parámetros a través de reutilización de características y logró excelente rendimiento con menos parámetros que arquitecturas tradicionales.",
          de: "DenseNet verband jede Schicht mit jeder nachfolgenden Schicht in feed-forward Weise und schuf extrem dichte Konnektivität. Dieses Design verbesserte Gradientenfluss, reduzierte Parameter durch Feature-Wiederverwendung und erreichte exzellente Leistung mit weniger Parametern als traditionelle Architekturen.",
          nl: "DenseNet verbond elke laag met elke volgende laag op een feed-forward manier, wat extreem dichte connectiviteit creëerde. Dit ontwerp verbeterde gradiënt flow, verminderde parameters door feature hergebruik en behaalde uitstekende prestaties met minder parameters dan traditionele architecturen."
        }
      },
      {
        question: {
          en: "What was the impact of transfer learning and pre-trained models in the deep learning revolution?",
          es: "¿Cuál fue el impacto del aprendizaje por transferencia y modelos pre-entrenados en la revolución del aprendizaje profundo?",
          de: "Was war die Auswirkung von Transfer Learning und vortrainierten Modellen in der Deep Learning-Revolution?",
          nl: "Wat was de impact van transfer learning en voorgetrainde modellen in de deep learning revolutie?"
        },
        options: [
          { en: "It enabled researchers and practitioners to leverage pre-trained networks for new tasks with limited data", es: "Permitió a investigadores y profesionales aprovechar redes pre-entrenadas para nuevas tareas con datos limitados", de: "Es ermöglichte Forschern und Praktikern vortrainierte Netzwerke für neue Aufgaben mit begrenzten Daten zu nutzen", nl: "Het stelde onderzoekers en praktijkers in staat voorgetrainde netwerken te benutten voor nieuwe taken met beperkte data" },
          { en: "It eliminated the need for computers", es: "Eliminó la necesidad de computadoras", de: "Es eliminierte die Notwendigkeit von Computern", nl: "Het elimineerde de behoefte aan computers" },
          { en: "It solved world hunger", es: "Resolvió el hambre mundial", de: "Es löste den Welthunger", nl: "Het loste wereldhonger op" },
          { en: "It created time machines", es: "Creó máquinas del tiempo", de: "Es schuf Zeitmaschinen", nl: "Het creëerde tijdmachines" }
        ],
        correct: 0,
        explanation: {
          en: "Transfer learning democratized deep learning by allowing practitioners to use models pre-trained on large datasets (like ImageNet) as starting points for new tasks. This approach dramatically reduced training time, data requirements, and computational resources needed for achieving good performance.",
          es: "El aprendizaje por transferencia democratizó el aprendizaje profundo permitiendo a profesionales usar modelos pre-entrenados en grandes conjuntos de datos (como ImageNet) como puntos de partida para nuevas tareas. Este enfoque redujo dramáticamente tiempo de entrenamiento, requisitos de datos y recursos computacionales necesarios para lograr buen rendimiento.",
          de: "Transfer Learning demokratisierte Deep Learning indem es Praktikern erlaubte auf großen Datensätzen (wie ImageNet) vortrainierte Modelle als Ausgangspunkte für neue Aufgaben zu verwenden. Dieser Ansatz reduzierte dramatisch Trainingszeit, Datenanforderungen und Rechenressourcen die für gute Leistung benötigt wurden.",
          nl: "Transfer learning democratiseerde deep learning door praktijkers toe te staan modellen voorgetraind op grote datasets (zoals ImageNet) te gebruiken als startpunten voor nieuwe taken. Deze benadering verminderde dramatisch trainingstijd, datavereisten en computationele bronnen nodig voor goede prestaties."
        }
      },
      {
        question: {
          en: "What was the role of deep learning frameworks like TensorFlow and PyTorch in the 2010s revolution?",
          es: "¿Cuál fue el papel de los marcos de aprendizaje profundo como TensorFlow y PyTorch en la revolución de los años 2010?",
          de: "Was war die Rolle von Deep Learning-Frameworks wie TensorFlow und PyTorch in der Revolution der 2010er?",
          nl: "Wat was de rol van deep learning frameworks zoals TensorFlow en PyTorch in de revolutie van de jaren 2010?"
        },
        options: [
          { en: "They democratized deep learning by providing accessible tools for building and training neural networks", es: "Democratizaron el aprendizaje profundo proporcionando herramientas accesibles para construir y entrenar redes neuronales", de: "Sie demokratisierten Deep Learning durch Bereitstellung zugänglicher Werkzeuge zum Bauen und Trainieren neuronaler Netzwerke", nl: "Ze democratiseerden deep learning door toegankelijke tools te bieden voor het bouwen en trainen van neurale netwerken" },
          { en: "They created the first computers", es: "Crearon las primeras computadoras", de: "Sie schufen die ersten Computer", nl: "Ze creëerden de eerste computers" },
          { en: "They solved climate change", es: "Resolvieron el cambio climático", de: "Sie lösten den Klimawandel", nl: "Ze losten klimaatverandering op" },
          { en: "They invented space travel", es: "Inventaron los viajes espaciales", de: "Sie erfanden Raumfahrt", nl: "Ze vonden ruimtereizen uit" }
        ],
        correct: 0,
        explanation: {
          en: "Deep learning frameworks provided high-level APIs, automatic differentiation, GPU support, and pre-built components that made deep learning accessible to a broader audience. TensorFlow (2015) and PyTorch (2016) became the dominant frameworks, accelerating research and deployment.",
          es: "Los marcos de aprendizaje profundo proporcionaron APIs de alto nivel, diferenciación automática, soporte GPU y componentes pre-construidos que hicieron accesible el aprendizaje profundo a una audiencia más amplia. TensorFlow (2015) y PyTorch (2016) se convirtieron en marcos dominantes, acelerando investigación y despliegue.",
          de: "Deep Learning-Frameworks boten high-level APIs, automatische Differentiation, GPU-Unterstützung und vorgefertigte Komponenten die Deep Learning einem breiteren Publikum zugänglich machten. TensorFlow (2015) und PyTorch (2016) wurden zu dominanten Frameworks und beschleunigten Forschung und Deployment.",
          nl: "Deep learning frameworks boden high-level APIs, automatische differentiatie, GPU ondersteuning en voorgebouwde componenten die deep learning toegankelijk maakten voor een breder publiek. TensorFlow (2015) en PyTorch (2016) werden de dominante frameworks, wat onderzoek en deployment versnelde."
        }
      },
      {
        question: {
          en: "What legacy did the deep learning breakthrough of the 2010s leave for modern AI?",
          es: "¿Qué legado dejó el avance del aprendizaje profundo de los años 2010 para la IA moderna?",
          de: "Welches Vermächtnis hinterließ der Deep Learning-Durchbruch der 2010er für moderne KI?",
          nl: "Welke erfenis liet de deep learning doorbraak van de jaren 2010 achter voor moderne AI?"
        },
        options: [
          { en: "It established deep neural networks as the dominant paradigm for AI across vision, language, and other domains", es: "Estableció las redes neuronales profundas como el paradigma dominante para IA en visión, lenguaje y otros dominios", de: "Es etablierte tiefe neuronale Netzwerke als dominantes Paradigma für KI in Vision, Sprache und anderen Bereichen", nl: "Het vestigde diepe neurale netwerken als het dominante paradigma voor AI in vision, taal en andere domeinen" },
          { en: "It proved that AI was impossible", es: "Probó que la IA era imposible", de: "Es bewies dass KI unmöglich war", nl: "Het bewees dat AI onmogelijk was" },
          { en: "It had no lasting impact", es: "No tuvo impacto duradero", de: "Es hatte keine dauerhafte Auswirkung", nl: "Het had geen blijvende impact" },
          { en: "It only improved computer graphics", es: "Solo mejoró los gráficos por computadora", de: "Es verbesserte nur Computergrafik", nl: "Het verbeterde alleen computergraphics" }
        ],
        correct: 0,
        explanation: {
          en: "The 2010s deep learning revolution fundamentally transformed AI, establishing neural networks as the dominant approach across computer vision, natural language processing, speech recognition, and many other domains. It created the foundation for modern AI systems including large language models, computer vision applications, and generative AI.",
          es: "La revolución del aprendizaje profundo de los años 2010 transformó fundamentalmente la IA, estableciendo las redes neuronales como el enfoque dominante en visión por computadora, procesamiento de lenguaje natural, reconocimiento de voz y muchos otros dominios. Creó la base para sistemas de IA modernos incluyendo modelos de lenguaje grandes, aplicaciones de visión por computadora e IA generativa.",
          de: "Die Deep Learning-Revolution der 2010er transformierte KI fundamental und etablierte neuronale Netzwerke als dominanten Ansatz in Computer Vision, natürlicher Sprachverarbeitung, Spracherkennung und vielen anderen Bereichen. Sie schuf die Grundlage für moderne KI-Systeme einschließlich großer Sprachmodelle, Computer Vision-Anwendungen und generativer KI.",
          nl: "De deep learning revolutie van de jaren 2010 transformeerde AI fundamenteel, vestigde neurale netwerken als de dominante benadering in computer vision, natuurlijke taalverwerking, spraakherkenning en vele andere domeinen. Het creëerde de basis voor moderne AI systemen inclusief grote taalmodellen, computer vision toepassingen en generatieve AI."
        }
      },
      {
        question: {
          en: "What was the significance of the ReLU (Rectified Linear Unit) activation function in the deep learning revolution?",
          es: "¿Cuál fue la importancia de la función de activación ReLU (Unidad Lineal Rectificada) en la revolución del aprendizaje profundo?",
          de: "Was war die Bedeutung der ReLU (Rectified Linear Unit) Aktivierungsfunktion in der Deep Learning-Revolution?",
          nl: "Wat was de betekenis van de ReLU (Rectified Linear Unit) activatiefunctie in de deep learning revolutie?"
        },
        options: [
          { en: "It solved the vanishing gradient problem and enabled training of much deeper networks", es: "Resolvió el problema del gradiente que desaparece y permitió entrenar redes mucho más profundas", de: "Es löste das Problem des verschwindenden Gradienten und ermöglichte das Training viel tieferer Netzwerke", nl: "Het loste het verdwijnende gradiënt probleem op en maakte training van veel diepere netwerken mogelijk" },
          { en: "It was the first activation function ever invented", es: "Fue la primera función de activación jamás inventada", de: "Es war die erste jemals erfundene Aktivierungsfunktion", nl: "Het was de eerste activatiefunctie ooit uitgevonden" },
          { en: "It created artificial consciousness", es: "Creó conciencia artificial", de: "Es schuf künstliches Bewusstsein", nl: "Het creëerde kunstmatig bewustzijn" },
          { en: "It solved natural language processing", es: "Resolvió el procesamiento de lenguaje natural", de: "Es löste natürliche Sprachverarbeitung", nl: "Het loste natuurlijke taalverwerking op" }
        ],
        correct: 0,
        explanation: {
          en: "ReLU activation (f(x) = max(0,x)) replaced sigmoid and tanh functions in deep networks because it doesn't saturate for positive values, maintaining gradients during backpropagation. This simple change was crucial for training much deeper networks effectively, contributing significantly to the deep learning revolution.",
          es: "La activación ReLU (f(x) = max(0,x)) reemplazó las funciones sigmoide y tanh en redes profundas porque no se satura para valores positivos, manteniendo gradientes durante la retropropagación. Este cambio simple fue crucial para entrenar redes mucho más profundas efectivamente, contribuyendo significativamente a la revolución del aprendizaje profundo.",
          de: "ReLU-Aktivierung (f(x) = max(0,x)) ersetzte Sigmoid- und Tanh-Funktionen in tiefen Netzwerken weil sie für positive Werte nicht sättigt und Gradienten während Backpropagation aufrechterhält. Diese einfache Änderung war entscheidend für effektives Training viel tieferer Netzwerke und trug erheblich zur Deep Learning-Revolution bei.",
          nl: "ReLU activatie (f(x) = max(0,x)) verving sigmoid en tanh functies in diepe netwerken omdat het niet verzadigt voor positieve waarden, waardoor gradiënten behouden blijven tijdens backpropagation. Deze eenvoudige verandering was cruciaal voor het effectief trainen van veel diepere netwerken, wat significant bijdroeg aan de deep learning revolutie."
        }
      }
    ]
  };

  if (typeof module !== 'undefined' && module.exports) {
    module.exports = level7;
  } else if (typeof window !== 'undefined') {
    window.level7 = level7;
  }
})();