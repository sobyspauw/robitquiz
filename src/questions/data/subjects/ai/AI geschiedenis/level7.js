// AI History Quiz - Level 7: Deep Learning Breakthrough (2010s)
(function() {
  const level7 = {
    name: {
      en: "AI History Level 7",
      es: "Historia de IA Nivel 7",
      de: "KI-Geschichte Stufe 7",
      nl: "AI Geschiedenis Level 7"
    },
    questions: [
      {
        question: {
          en: "What was the significance of AlexNet's victory in the 2012 ImageNet competition?",
          es: "¿Cuál fue la importancia de la victoria de AlexNet en la competencia ImageNet de 2012?",
          de: "Was war die Bedeutung von AlexNets Sieg im ImageNet-Wettbewerb 2012?",
          nl: "Wat was de betekenis van AlexNet's overwinning in de ImageNet competitie van 2012?"
        },
        options: [
          { en: "It sparked the modern deep learning revolution", es: "Desencadenó la revolución moderna del aprendizaje profundo", de: "Es löste die moderne Deep Learning-Revolution aus", nl: "Het veroorzaakte de moderne deep learning revolutie" },
          { en: "It was the first neural network ever created", es: "Fue la primera red neuronal jamás creada", de: "Es war das erste jemals erstellte neuronale Netzwerk", nl: "Het was het eerste neurale netwerk ooit gemaakt" },
          { en: "It solved natural language processing", es: "Resolvió el procesamiento de lenguaje natural", de: "Es löste die natürliche Sprachverarbeitung", nl: "Het loste natuurlijke taalverwerking op" },
          { en: "It created the first chatbot", es: "Creó el primer chatbot", de: "Es schuf den ersten Chatbot", nl: "Het creëerde de eerste chatbot" }
        ],
        correct: 0,
        explanation: {
          en: "AlexNet's dramatic victory by a large margin demonstrated the power of deep convolutional neural networks and GPU computing, triggering widespread adoption of deep learning across industries and research.",
          es: "La victoria dramática de AlexNet por un gran margen demostró el poder de las redes neuronales convolucionales profundas y la computación GPU, desencadenando la adopción generalizada del aprendizaje profundo en industrias e investigación.",
          de: "AlexNets dramatischer Sieg mit großem Vorsprung demonstrierte die Macht tiefer Convolutional Neural Networks und GPU-Computing und löste eine weitverbreitete Adoption von Deep Learning in Industrien und Forschung aus.",
          nl: "AlexNet's dramatische overwinning met een grote marge toonde de kracht van diepe convolutionele neurale netwerken en GPU computing, wat wijdverspreide adoptie van deep learning in industrieën en onderzoek veroorzaakte."
        }
      },
      {
        question: {
          en: "What was the significance of Geoffrey Hinton's work on deep belief networks in 2006?",
          es: "¿Cuál fue la importancia del trabajo de Geoffrey Hinton sobre redes de creencia profunda en 2006?",
          de: "Was war die Bedeutung von Geoffrey Hintons Arbeit an Deep Belief Networks 2006?",
          nl: "Wat was de betekenis van Geoffrey Hinton's werk aan deep belief networks in 2006?"
        },
        options: [
          { en: "It showed how to train deep neural networks effectively", es: "Mostró cómo entrenar redes neuronales profundas efectivamente", de: "Es zeigte wie man tiefe neuronale Netzwerke effektiv trainiert", nl: "Het toonde hoe diepe neurale netwerken effectief te trainen" },
          { en: "It created the first computer vision system", es: "Creó el primer sistema de visión por computadora", de: "Es schuf das erste Computer Vision-System", nl: "Het creëeerde het eerste computer vision systeem" },
          { en: "It solved the traveling salesman problem", es: "Resolvió el problema del vendedor viajero", de: "Es löste das Traveling Salesman-Problem", nl: "Het loste het handelsreizigersprobleem op" },
          { en: "It invented machine learning", es: "Inventó el aprendizaje automático", de: "Es erfand maschinelles Lernen", nl: "Het vond machine learning uit" }
        ],
        correct: 0,
        explanation: {
          en: "Hinton's 2006 paper on deep belief networks demonstrated effective layer-by-layer pre-training, overcoming the vanishing gradient problem and proving that deep neural networks could be trained successfully, launching the modern deep learning era.",
          es: "El artículo de Hinton de 2006 sobre redes de creencia profunda demostró pre-entrenamiento efectivo capa por capa, superando el problema del gradiente que desaparece y probando que las redes neuronales profundas podían entrenarse exitosamente, lanzando la era moderna del aprendizaje profundo.",
          de: "Hintons 2006 Arbeit über Deep Belief Networks demonstrierte effektives schichtweises Vortraining, überwand das Problem des verschwindenden Gradienten und bewies dass tiefe neuronale Netzwerke erfolgreich trainiert werden konnten, was die moderne Deep Learning-Ära einläutete.",
          nl: "Hinton's 2006 paper over deep belief networks toonde effectieve laag-voor-laag pre-training, overkomend het verdwijnende gradiënt probleem en bewees dat diepe neurale netwerken succesvol getraind konden worden, wat het moderne deep learning tijdperk inluidde."
        }
      },
      {
        question: {
          en: "What was the importance of the development of Word2Vec by Tomas Mikolov and colleagues in 2013?",
          es: "¿Cuál fue la importancia del desarrollo de Word2Vec por Tomas Mikolov y colegas en 2013?",
          de: "Was war die Wichtigkeit der Entwicklung von Word2Vec durch Tomas Mikolov und Kollegen 2013?",
          nl: "Wat was het belang van de ontwikkeling van Word2Vec door Tomas Mikolov en collega's in 2013?"
        },
        options: [
          { en: "It created vector representations of words that captured semantic relationships", es: "Creó representaciones vectoriales de palabras que capturaron relaciones semánticas", de: "Es schuf Vektordarstellungen von Wörtern die semantische Beziehungen erfassten", nl: "Het creëerde vectorrepresentaties van woorden die semantische relaties vastlegden" },
          { en: "It solved computer graphics", es: "Resolvió gráficos por computadora", de: "Es löste Computergrafik", nl: "Het loste computergraphics op" },
          { en: "It invented databases", es: "Inventó bases de datos", de: "Es erfand Datenbanken", nl: "Het vond databases uit" },
          { en: "It created operating systems", es: "Creó sistemas operativos", de: "Es schuf Betriebssysteme", nl: "Het creëerde besturingssystemen" }
        ],
        correct: 0,
        explanation: {
          en: "Word2Vec demonstrated that neural networks could learn dense vector representations of words that captured semantic and syntactic relationships, enabling operations like 'king - man + woman = queen' and revolutionizing natural language processing.",
          es: "Word2Vec demostró que las redes neuronales podían aprender representaciones vectoriales densas de palabras que capturaron relaciones semánticas y sintácticas, permitiendo operaciones como 'rey - hombre + mujer = reina' y revolucionando el procesamiento de lenguaje natural.",
          de: "Word2Vec demonstrierte dass neuronale Netzwerke dichte Vektordarstellungen von Wörtern lernen konnten die semantische und syntaktische Beziehungen erfassten, was Operationen wie 'König - Mann + Frau = Königin' ermöglichte und die natürliche Sprachverarbeitung revolutionierte.",
          nl: "Word2Vec toonde aan dat neurale netwerken dichte vectorrepresentaties van woorden konden leren die semantische en syntactische relaties vastlegden, waardoor operaties zoals 'koning - man + vrouw = koningin' mogelijk werden en natuurlijke taalverwerking revolutioneerden."
        }
      },
      {
        question: {
          en: "What was the significance of the development of Generative Adversarial Networks (GANs) by Ian Goodfellow in 2014?",
          es: "¿Cuál fue la importancia del desarrollo de Redes Adversarias Generativas (GAN) por Ian Goodfellow en 2014?",
          de: "Was war die Bedeutung der Entwicklung von Generative Adversarial Networks (GANs) durch Ian Goodfellow 2014?",
          nl: "Wat was de betekenis van de ontwikkeling van Generative Adversarial Networks (GANs) door Ian Goodfellow in 2014?"
        },
        options: [
          { en: "They revolutionized generative modeling by having two networks compete against each other", es: "Revolucionaron el modelado generativo haciendo que dos redes compitieran entre sí", de: "Sie revolutionierten generative Modellierung indem zwei Netzwerke gegeneinander konkurrierten", nl: "Ze revolutioneerden generatieve modellering door twee netwerken tegen elkaar te laten concurreren" },
          { en: "They solved natural language processing", es: "Resolvieron el procesamiento de lenguaje natural", de: "Sie lösten natürliche Sprachverarbeitung", nl: "Ze losten natuurlijke taalverwerking op" },
          { en: "They created the first neural network", es: "Crearon la primera red neuronal", de: "Sie schufen das erste neuronale Netzwerk", nl: "Ze creëerden het eerste neurale netwerk" },
          { en: "They invented reinforcement learning", es: "Inventaron el aprendizaje por refuerzo", de: "Sie erfanden Reinforcement Learning", nl: "Ze vonden reinforcement learning uit" }
        ],
        correct: 0,
        explanation: {
          en: "GANs introduced a novel training paradigm where a generator network creates fake data while a discriminator network tries to detect fakes, leading to remarkable advances in image generation, data augmentation, and creative AI applications.",
          es: "Los GAN introdujeron un paradigma de entrenamiento novedoso donde una red generadora crea datos falsos mientras una red discriminadora trata de detectar falsificaciones, llevando a avances notables en generación de imágenes, aumento de datos y aplicaciones de IA creativa.",
          de: "GANs führten ein neuartiges Trainingsparadigma ein bei dem ein Generator-Netzwerk falsche Daten erstellt während ein Diskriminator-Netzwerk versucht Fälschungen zu erkennen, was zu bemerkenswerten Fortschritten in Bildgenerierung, Datenaugmentierung und kreativen KI-Anwendungen führte.",
          nl: "GANs introduceerden een nieuw trainingsparadigma waarbij een generatornetwerk valse data creëert terwijl een discriminatornetwerk probeert vervalsingen te detecteren, leidend tot opmerkelijke vooruitgang in beeldgeneratie, data-augmentatie en creatieve AI toepassingen."
        }
      },
      {
        question: {
          en: "What was the significance of the development of Long Short-Term Memory (LSTM) networks by Hochreiter and Schmidhuber in 1997?",
          es: "¿Cuál fue la importancia del desarrollo de redes de Memoria a Largo y Corto Plazo (LSTM) por Hochreiter y Schmidhuber en 1997?",
          de: "Was war die Bedeutung der Entwicklung von Long Short-Term Memory (LSTM) Netzwerken durch Hochreiter und Schmidhuber 1997?",
          nl: "Wat was de betekenis van de ontwikkeling van Long Short-Term Memory (LSTM) netwerken door Hochreiter en Schmidhuber in 1997?"
        },
        options: [
          { en: "They solved the vanishing gradient problem in recurrent neural networks", es: "Resolvieron el problema del gradiente que desaparece en redes neuronales recurrentes", de: "Sie lösten das Problem des verschwindenden Gradienten in rekurrenten neuronalen Netzwerken", nl: "Ze losten het verdwijnende gradiënt probleem in recurrente neurale netwerken op" },
          { en: "They created the first computer", es: "Crearon la primera computadora", de: "Sie schufen den ersten Computer", nl: "Ze creëerden de eerste computer" },
          { en: "They invented programming languages", es: "Inventaron lenguajes de programación", de: "Sie erfanden Programmiersprachen", nl: "Ze vonden programmeertalen uit" },
          { en: "They solved database management", es: "Resolvieron gestión de bases de datos", de: "Sie lösten Datenbankmanagement", nl: "Ze losten database management op" }
        ],
        correct: 0,
        explanation: {
          en: "LSTM networks addressed the vanishing gradient problem that plagued traditional RNNs, enabling neural networks to learn long-term dependencies in sequential data. This breakthrough was crucial for advances in speech recognition, machine translation, and natural language processing.",
          es: "Las redes LSTM abordaron el problema del gradiente que desaparece que afectaba las RNN tradicionales, permitiendo a las redes neuronales aprender dependencias a largo plazo en datos secuenciales. Este avance fue crucial para avances en reconocimiento de voz, traducción automática y procesamiento de lenguaje natural.",
          de: "LSTM-Netzwerke lösten das Problem des verschwindenden Gradienten das traditionelle RNNs plagte, was neuronalen Netzwerken ermöglichte langfristige Abhängigkeiten in sequenziellen Daten zu lernen. Dieser Durchbruch war entscheidend für Fortschritte in Spracherkennung, maschineller Übersetzung und natürlicher Sprachverarbeitung.",
          nl: "LSTM netwerken pakten het verdwijnende gradiënt probleem aan dat traditionele RNNs plaagde, waardoor neurale netwerken lange termijn afhankelijkheden in sequentiële data konden leren. Deze doorbraak was cruciaal voor vooruitgang in spraakherkenning, machinevertaling en natuurlijke taalverwerking."
        }
      },
      {
        question: {
          en: "What was the impact of the development of VGGNet by the Visual Geometry Group at Oxford in 2014?",
          es: "¿Cuál fue el impacto del desarrollo de VGGNet por el Visual Geometry Group en Oxford en 2014?",
          de: "Was war die Auswirkung der Entwicklung von VGGNet durch die Visual Geometry Group in Oxford 2014?",
          nl: "Wat was de impact van de ontwikkeling van VGGNet door de Visual Geometry Group in Oxford in 2014?"
        },
        options: [
          { en: "It demonstrated that very deep networks with small filters could achieve excellent performance", es: "Demostró que redes muy profundas con filtros pequeños podían lograr excelente rendimiento", de: "Es demonstrierte dass sehr tiefe Netzwerke mit kleinen Filtern exzellente Leistung erreichen konnten", nl: "Het toonde aan dat zeer diepe netwerken met kleine filters uitstekende prestaties konden behalen" },
          { en: "It created the first web browser", es: "Creó el primer navegador web", de: "Es schuf den ersten Webbrowser", nl: "Het creëerde de eerste webbrowser" },
          { en: "It solved quantum mechanics", es: "Resolvió la mecánica cuántica", de: "Es löste die Quantenmechanik", nl: "Het loste quantummechanica op" },
          { en: "It invented machine translation", es: "Inventó la traducción automática", de: "Es erfand maschinelle Übersetzung", nl: "Het vond machinevertaling uit" }
        ],
        correct: 0,
        explanation: {
          en: "VGGNet showed that depth was crucial for good performance by using very small 3x3 convolutional filters stacked in deep architectures. It demonstrated that systematic increase in depth with small filters was more effective than using larger filters, influencing many subsequent architectures.",
          es: "VGGNet mostró que la profundidad era crucial para buen rendimiento usando filtros convolucionales muy pequeños de 3x3 apilados en arquitecturas profundas. Demostró que el aumento sistemático en profundidad con filtros pequeños era más efectivo que usar filtros más grandes, influyendo en muchas arquitecturas posteriores.",
          de: "VGGNet zeigte dass Tiefe entscheidend für gute Leistung war durch Verwendung sehr kleiner 3x3 Faltungsfilter gestapelt in tiefen Architekturen. Es demonstrierte dass systematische Zunahme der Tiefe mit kleinen Filtern effektiver war als größere Filter zu verwenden, was viele nachfolgende Architekturen beeinflusste.",
          nl: "VGGNet toonde aan dat diepte cruciaal was voor goede prestaties door zeer kleine 3x3 convolutie filters te gebruiken gestapeld in diepe architecturen. Het toonde aan dat systematische toename in diepte met kleine filters effectiever was dan het gebruik van grotere filters, wat veel volgende architecturen beïnvloedde."
        }
      },
      {
        question: {
          en: "What was the significance of the development of ResNet (Residual Networks) by Microsoft Research in 2015?",
          es: "¿Cuál fue la importancia del desarrollo de ResNet (Redes Residuales) por Microsoft Research en 2015?",
          de: "Was war die Bedeutung der Entwicklung von ResNet (Residual Networks) durch Microsoft Research 2015?",
          nl: "Wat was de betekenis van de ontwikkeling van ResNet (Residual Networks) door Microsoft Research in 2015?"
        },
        options: [
          { en: "It solved the degradation problem in very deep neural networks", es: "Resolvió el problema de degradación en redes neuronales muy profundas", de: "Es löste das Degradationsproblem in sehr tiefen neuronalen Netzwerken", nl: "Het loste het degradatieprobleem in zeer diepe neurale netwerken op" },
          { en: "It created the first AI system", es: "Creó el primer sistema de IA", de: "Es schuf das erste KI-System", nl: "Het creëerde het eerste AI systeem" },
          { en: "It invented machine learning", es: "Inventó el aprendizaje automático", de: "Es erfand maschinelles Lernen", nl: "Het vond machine learning uit" },
          { en: "It solved speech recognition", es: "Resolvió el reconocimiento de voz", de: "Es löste Spracherkennung", nl: "Het loste spraakherkenning op" }
        ],
        correct: 0,
        explanation: {
          en: "ResNet introduced skip connections that allowed gradients to flow directly to earlier layers, solving the degradation problem where deeper networks performed worse than shallow ones, enabling the training of networks with hundreds of layers.",
          es: "ResNet introdujo conexiones de salto que permitieron a los gradientes fluir directamente a capas anteriores, resolviendo el problema de degradación donde redes más profundas tuvieron peor rendimiento que las superficiales, permitiendo entrenar redes con cientos de capas.",
          de: "ResNet führte Skip-Verbindungen ein die Gradienten erlaubten direkt zu früheren Schichten zu fließen, löste das Degradationsproblem bei dem tiefere Netzwerke schlechter abschnitten als flache, und ermöglichte das Training von Netzwerken mit Hunderten von Schichten.",
          nl: "ResNet introduceerde skip-verbindingen die gradiënten toestonden direct naar eerdere lagen te stromen, het degradatieprobleem oplossend waarbij diepere netwerken slechter presteerden dan ondiepe, waardoor training van netwerken met honderden lagen mogelijk werd."
        }
      },
      {
        question: {
          en: "What was the contribution of Yoshua Bengio's work on attention mechanisms in neural networks?",
          es: "¿Cuál fue la contribución del trabajo de Yoshua Bengio sobre mecanismos de atención en redes neuronales?",
          de: "Was war der Beitrag von Yoshua Bengios Arbeit über Aufmerksamkeitsmechanismen in neuronalen Netzwerken?",
          nl: "Wat was de bijdrage van Yoshua Bengio's werk aan aandachtsmechanismen in neurale netwerken?"
        },
        options: [
          { en: "He enabled neural networks to focus on relevant parts of input sequences", es: "Permitió a las redes neuronales enfocarse en partes relevantes de secuencias de entrada", de: "Er ermöglichte neuronalen Netzwerken sich auf relevante Teile von Eingabesequenzen zu konzentrieren", nl: "Hij stelde neurale netwerken in staat om te focussen op relevante delen van invoersequenties" },
          { en: "He created the first computer", es: "Creó la primera computadora", de: "Er schuf den ersten Computer", nl: "Hij creëerde de eerste computer" },
          { en: "He invented the internet", es: "Inventó internet", de: "Er erfand das Internet", nl: "Hij vond het internet uit" },
          { en: "He solved quantum computing", es: "Resolvió la computación cuántica", de: "Er löste Quantencomputing", nl: "Hij loste quantum computing op" }
        ],
        correct: 0,
        explanation: {
          en: "Bengio's work on attention mechanisms, particularly in the context of neural machine translation, allowed networks to selectively focus on different parts of input sequences, dramatically improving performance and laying groundwork for the Transformer architecture.",
          es: "El trabajo de Bengio sobre mecanismos de atención, particularmente en el contexto de traducción automática neuronal, permitió a las redes enfocarse selectivamente en diferentes partes de secuencias de entrada, mejorando dramáticamente el rendimiento y sentando las bases para la arquitectura Transformer.",
          de: "Bengios Arbeit über Aufmerksamkeitsmechanismen, besonders im Kontext neuronaler maschineller Übersetzung, erlaubte Netzwerken sich selektiv auf verschiedene Teile von Eingabesequenzen zu konzentrieren, was die Leistung dramatisch verbesserte und den Grundstein für die Transformer-Architektur legte.",
          nl: "Bengio's werk aan aandachtsmechanismen, vooral in de context van neurale machinevertaling, stelde netwerken in staat om selectief te focussen op verschillende delen van invoersequenties, wat de prestaties dramatisch verbeterde en de basis legde voor de Transformer architectuur."
        }
      },
      {
        question: {
          en: "What was the impact of the introduction of batch normalization by Ioffe and Szegedy in 2015?",
          es: "¿Cuál fue el impacto de la introducción de normalización por lotes por Ioffe y Szegedy en 2015?",
          de: "Was war die Auswirkung der Einführung von Batch-Normalisierung durch Ioffe und Szegedy 2015?",
          nl: "Wat was de impact van de introductie van batch normalization door Ioffe en Szegedy in 2015?"
        },
        options: [
          { en: "It significantly accelerated deep network training and improved stability", es: "Aceleró significativamente el entrenamiento de redes profundas y mejoró la estabilidad", de: "Es beschleunigte das Training tiefer Netzwerke erheblich und verbesserte die Stabilität", nl: "Het versnelde aanzienlijk het trainen van diepe netwerken en verbeterde de stabiliteit" },
          { en: "It created the first neural network", es: "Creó la primera red neuronal", de: "Es schuf das erste neuronale Netzwerk", nl: "Het creëerde het eerste neurale netwerk" },
          { en: "It solved the halting problem", es: "Resolvió el problema de la parada", de: "Es löste das Halteproblem", nl: "Het loste het halting probleem op" },
          { en: "It invented parallel computing", es: "Inventó la computación paralela", de: "Es erfand paralleles Computing", nl: "Het vond parallel computing uit" }
        ],
        correct: 0,
        explanation: {
          en: "Batch normalization normalized the inputs to each layer, reducing internal covariate shift and allowing for higher learning rates, faster convergence, and more stable training of deep neural networks. It became a standard component in most modern architectures.",
          es: "La normalización por lotes normalizó las entradas a cada capa, reduciendo el cambio de covariable interno y permitiendo tasas de aprendizaje más altas, convergencia más rápida y entrenamiento más estable de redes neuronales profundas. Se convirtió en un componente estándar en la mayoría de arquitecturas modernas.",
          de: "Batch-Normalisierung normalisierte die Eingaben zu jeder Schicht, reduzierte interne Kovariatenverschiebung und ermöglichte höhere Lernraten, schnellere Konvergenz und stabileres Training tiefer neuronaler Netzwerke. Es wurde zu einer Standardkomponente in den meisten modernen Architekturen.",
          nl: "Batch normalization normaliseerde de inputs naar elke laag, verminderde interne covariate shift en maakte hogere leersnelheden, snellere convergentie en stabielere training van diepe neurale netwerken mogelijk. Het werd een standaardcomponent in de meeste moderne architecturen."
        }
      },
      {
        question: {
          en: "What was the significance of the GoogLeNet/Inception architecture developed by Google in 2014?",
          es: "¿Cuál fue la importancia de la arquitectura GoogLeNet/Inception desarrollada por Google en 2014?",
          de: "Was war die Bedeutung der GoogLeNet/Inception-Architektur entwickelt von Google 2014?",
          nl: "Wat was de betekenis van de GoogLeNet/Inception architectuur ontwikkeld door Google in 2014?"
        },
        options: [
          { en: "It introduced the concept of inception modules with multi-scale feature extraction", es: "Introdujo el concepto de módulos inception con extracción de características multi-escala", de: "Es führte das Konzept von Inception-Modulen mit multi-skaliger Feature-Extraktion ein", nl: "Het introduceerde het concept van inception modules met multi-schaal feature extractie" },
          { en: "It created the first search engine", es: "Creó el primer motor de búsqueda", de: "Es schuf die erste Suchmaschine", nl: "Het creëerde de eerste zoekmachine" },
          { en: "It solved natural language processing", es: "Resolvió el procesamiento de lenguaje natural", de: "Es löste natürliche Sprachverarbeitung", nl: "Het loste natuurlijke taalverwerking op" },
          { en: "It invented mobile computing", es: "Inventó la computación móvil", de: "Es erfand mobiles Computing", nl: "Het vond mobiele computing uit" }
        ],
        correct: 0,
        explanation: {
          en: "GoogLeNet introduced inception modules that applied multiple convolutional filters of different sizes in parallel, allowing the network to capture features at multiple scales efficiently. This innovation reduced parameters while maintaining performance and influenced many subsequent architectures.",
          es: "GoogLeNet introdujo módulos inception que aplicaron múltiples filtros convolucionales de diferentes tamaños en paralelo, permitiendo a la red capturar características en múltiples escalas eficientemente. Esta innovación redujo parámetros mientras mantuvo rendimiento e influyó en muchas arquitecturas posteriores.",
          de: "GoogLeNet führte Inception-Module ein die multiple Faltungsfilter verschiedener Größen parallel anwendeten, was dem Netzwerk erlaubte Features auf mehreren Skalen effizient zu erfassen. Diese Innovation reduzierte Parameter während die Leistung beibehalten wurde und beeinflusste viele nachfolgende Architekturen.",
          nl: "GoogLeNet introduceerde inception modules die meerdere convolutionele filters van verschillende groottes parallel toepasten, waardoor het netwerk features op meerdere schalen efficiënt kon vastleggen. Deze innovatie verminderde parameters terwijl prestaties behouden bleven en beïnvloedde veel volgende architecturen."
        }
      },
      {
        question: {
          en: "What was the role of GPU computing in enabling the deep learning revolution of the 2010s?",
          es: "¿Cuál fue el papel de la computación GPU en permitir la revolución del aprendizaje profundo de los años 2010?",
          de: "Was war die Rolle von GPU-Computing beim Ermöglichen der Deep Learning-Revolution der 2010er?",
          nl: "Wat was de rol van GPU computing in het mogelijk maken van de deep learning revolutie van de jaren 2010?"
        },
        options: [
          { en: "GPUs provided the massive parallel processing power needed to train large neural networks efficiently", es: "Los GPU proporcionaron el poder de procesamiento paralelo masivo necesario para entrenar grandes redes neuronales eficientemente", de: "GPUs boten die massive parallele Verarbeitungsleistung die benötigt wurde um große neuronale Netzwerke effizient zu trainieren", nl: "GPU's boden de massieve parallelle verwerkingskracht die nodig was om grote neurale netwerken efficiënt te trainen" },
          { en: "GPUs made computers cheaper", es: "Los GPU hicieron las computadoras más baratas", de: "GPUs machten Computer billiger", nl: "GPU's maakten computers goedkoper" },
          { en: "GPUs invented the internet", es: "Los GPU inventaron internet", de: "GPUs erfanden das Internet", nl: "GPU's vonden het internet uit" },
          { en: "GPUs solved all programming problems", es: "Los GPU resolvieron todos los problemas de programación", de: "GPUs lösten alle Programmierproblem", nl: "GPU's losten alle programmeerproblemen op" }
        ],
        correct: 0,
        explanation: {
          en: "GPUs' highly parallel architecture was ideal for the matrix operations in neural network training. NVIDIA's CUDA programming model and later frameworks like cuDNN made deep learning accessible, reducing training times from months to days and enabling the practical training of large models.",
          es: "La arquitectura altamente paralela de los GPU era ideal para las operaciones matriciales en entrenamiento de redes neuronales. El modelo de programación CUDA de NVIDIA y marcos posteriores como cuDNN hicieron accesible el aprendizaje profundo, reduciendo tiempos de entrenamiento de meses a días y permitiendo entrenamiento práctico de modelos grandes.",
          de: "GPUs hochparallele Architektur war ideal für die Matrixoperationen im neuronalen Netzwerk-Training. NVIDIAs CUDA-Programmiermodell und spätere Frameworks wie cuDNN machten Deep Learning zugänglich, reduzierten Trainingszeiten von Monaten auf Tage und ermöglichten praktisches Training großer Modelle.",
          nl: "GPU's zeer parallelle architectuur was ideaal voor de matrixoperaties in neurale netwerk training. NVIDIA's CUDA programmeermodel en latere frameworks zoals cuDNN maakten deep learning toegankelijk, verminderden trainingstijden van maanden naar dagen en maakten praktische training van grote modellen mogelijk."
        }
      },
      {
        question: {
          en: "What was the significance of the development of GloVe (Global Vectors) by Pennington et al. in 2014?",
          es: "¿Cuál fue la importancia del desarrollo de GloVe (Vectores Globales) por Pennington et al. en 2014?",
          de: "Was war die Bedeutung der Entwicklung von GloVe (Global Vectors) durch Pennington et al. 2014?",
          nl: "Wat was de betekenis van de ontwikkeling van GloVe (Global Vectors) door Pennington et al. in 2014?"
        },
        options: [
          { en: "It combined the advantages of matrix factorization and local context window methods for word embeddings", es: "Combinó las ventajas de factorización de matrices y métodos de ventana de contexto local para embeddings de palabras", de: "Es kombinierte die Vorteile von Matrixfaktorisierung und lokalen Kontextfenster-Methoden für Wort-Embeddings", nl: "Het combineerde de voordelen van matrixfactorisatie en lokale context venster methoden voor woord embeddings" },
          { en: "It created the first operating system", es: "Creó el primer sistema operativo", de: "Es schuf das erste Betriebssystem", nl: "Het creëerde het eerste besturingssysteem" },
          { en: "It solved quantum computing", es: "Resolvió la computación cuántica", de: "Es löste Quantencomputing", nl: "Het loste quantum computing op" },
          { en: "It invented virtual reality", es: "Inventó la realidad virtual", de: "Es erfand virtuelle Realität", nl: "Het vond virtual reality uit" }
        ],
        correct: 0,
        explanation: {
          en: "GloVe bridged the gap between count-based methods (like LSA) and prediction-based methods (like Word2Vec) by leveraging global statistical information while maintaining the semantic relationships. It became widely adopted for generating high-quality word embeddings.",
          es: "GloVe cerró la brecha entre métodos basados en conteo (como LSA) y métodos basados en predicción (como Word2Vec) aprovechando información estadística global mientras mantenía las relaciones semánticas. Se adoptó ampliamente para generar embeddings de palabras de alta calidad.",
          de: "GloVe überbrückte die Lücke zwischen zählbasierten Methoden (wie LSA) und vorhersagebasierten Methoden (wie Word2Vec) durch Nutzung globaler statistischer Informationen während semantische Beziehungen beibehalten wurden. Es wurde weit verbreitet zur Generierung hochwertiger Wort-Embeddings angenommen.",
          nl: "GloVe overbrugde de kloof tussen tel-gebaseerde methoden (zoals LSA) en voorspelling-gebaseerde methoden (zoals Word2Vec) door globale statistische informatie te benutten terwijl semantische relaties behouden bleven. Het werd breed aangenomen voor het genereren van hoogwaardige woord embeddings."
        }
      },
      {
        question: {
          en: "What was the impact of the development of Seq2Seq (Sequence-to-Sequence) models by Sutskever et al. in 2014?",
          es: "¿Cuál fue el impacto del desarrollo de modelos Seq2Seq (Secuencia-a-Secuencia) por Sutskever et al. en 2014?",
          de: "Was war die Auswirkung der Entwicklung von Seq2Seq (Sequence-to-Sequence) Modellen durch Sutskever et al. 2014?",
          nl: "Wat was de impact van de ontwikkeling van Seq2Seq (Sequence-to-Sequence) modellen door Sutskever et al. in 2014?"
        },
        options: [
          { en: "They enabled neural networks to handle variable-length input and output sequences for tasks like translation", es: "Permitieron a las redes neuronales manejar secuencias de entrada y salida de longitud variable para tareas como traducción", de: "Sie ermöglichten neuronalen Netzwerken variable Eingabe- und Ausgabesequenzen für Aufgaben wie Übersetzung zu handhaben", nl: "Ze stelden neurale netwerken in staat om variabele-lengte invoer en uitvoer sequenties te behandelen voor taken zoals vertaling" },
          { en: "They created the first database", es: "Crearon la primera base de datos", de: "Sie schufen die erste Datenbank", nl: "Ze creëerden de eerste database" },
          { en: "They solved image recognition", es: "Resolvieron el reconocimiento de imágenes", de: "Sie lösten Bilderkennung", nl: "Ze losten beeldherkenning op" },
          { en: "They invented social media", es: "Inventaron las redes sociales", de: "Sie erfanden soziale Medien", nl: "Ze vonden sociale media uit" }
        ],
        correct: 0,
        explanation: {
          en: "Seq2Seq models used an encoder-decoder architecture with LSTMs to map variable-length input sequences to variable-length output sequences. This approach revolutionized machine translation, text summarization, and dialogue systems, paving the way for more sophisticated sequence modeling.",
          es: "Los modelos Seq2Seq usaron una arquitectura codificador-decodificador con LSTM para mapear secuencias de entrada de longitud variable a secuencias de salida de longitud variable. Este enfoque revolucionó la traducción automática, resumen de texto y sistemas de diálogo, allanando el camino para modelado de secuencias más sofisticado.",
          de: "Seq2Seq-Modelle verwendeten eine Encoder-Decoder-Architektur mit LSTMs um variable Eingabesequenzen auf variable Ausgabesequenzen zu mappen. Dieser Ansatz revolutionierte maschinelle Übersetzung, Textzusammenfassung und Dialogsysteme und ebnete den Weg für anspruchsvollere Sequenzmodellierung.",
          nl: "Seq2Seq modellen gebruikten een encoder-decoder architectuur met LSTMs om variabele-lengte invoersequenties naar variabele-lengte uitvoersequenties te mappen. Deze benadering revolutioneerde machinevertaling, tekstsamenvatting en dialoogsystemen, waarmee de weg werd geëffend voor geavanceerdere sequentiemodellering."
        }
      },
      {
        question: {
          en: "What was the significance of dropout regularization introduced by Hinton et al. in 2012?",
          es: "¿Cuál fue la importancia de la regularización dropout introducida por Hinton et al. en 2012?",
          de: "Was war die Bedeutung der Dropout-Regularisierung eingeführt von Hinton et al. 2012?",
          nl: "Wat was de betekenis van dropout regularisatie geïntroduceerd door Hinton et al. in 2012?"
        },
        options: [
          { en: "It provided an effective way to prevent overfitting in deep neural networks", es: "Proporcionó una forma efectiva de prevenir sobreajuste en redes neuronales profundas", de: "Es bot eine effektive Weise Overfitting in tiefen neuronalen Netzwerken zu verhindern", nl: "Het bood een effectieve manier om overfitting in diepe neurale netwerken te voorkomen" },
          { en: "It made computers faster", es: "Hizo las computadoras más rápidas", de: "Es machte Computer schneller", nl: "Het maakte computers sneller" },
          { en: "It created artificial consciousness", es: "Creó conciencia artificial", de: "Es schuf künstliches Bewusstsein", nl: "Het creëerde kunstmatig bewustzijn" },
          { en: "It solved the energy crisis", es: "Resolvió la crisis energética", de: "Es löste die Energiekrise", nl: "Het loste de energiecrisis op" }
        ],
        correct: 0,
        explanation: {
          en: "Dropout randomly sets some neurons to zero during training, forcing the network to not rely on any single neuron. This simple but effective technique dramatically reduced overfitting in deep networks and became a standard regularization method in the deep learning toolkit.",
          es: "Dropout establece aleatoriamente algunas neuronas en cero durante el entrenamiento, forzando a la red a no depender de ninguna neurona individual. Esta técnica simple pero efectiva redujo dramáticamente el sobreajuste en redes profundas y se convirtió en un método estándar de regularización en el kit de herramientas de aprendizaje profundo.",
          de: "Dropout setzt zufällig einige Neuronen während des Trainings auf null, was das Netzwerk zwingt nicht auf einzelne Neuronen angewiesen zu sein. Diese einfache aber effektive Technik reduzierte Overfitting in tiefen Netzwerken dramatisch und wurde zu einer Standard-Regularisierungsmethode im Deep Learning-Toolkit.",
          nl: "Dropout zet willekeurig enkele neuronen op nul tijdens training, waardoor het netwerk wordt gedwongen niet te vertrouwen op een enkele neuron. Deze eenvoudige maar effectieve techniek verminderde overfitting in diepe netwerken dramatisch en werd een standaard regularisatiemethode in de deep learning toolkit."
        }
      },
      {
        question: {
          en: "What was the impact of the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) on deep learning development?",
          es: "¿Cuál fue el impacto del Desafío de Reconocimiento Visual a Gran Escala ImageNet (ILSVRC) en el desarrollo del aprendizaje profundo?",
          de: "Was war die Auswirkung der ImageNet Large Scale Visual Recognition Challenge (ILSVRC) auf die Deep Learning-Entwicklung?",
          nl: "Wat was de impact van de ImageNet Large Scale Visual Recognition Challenge (ILSVRC) op deep learning ontwikkeling?"
        },
        options: [
          { en: "It provided a standardized benchmark that drove innovation and competition in computer vision", es: "Proporcionó una referencia estandarizada que impulsó innovación y competencia en visión por computadora", de: "Es bot eine standardisierte Benchmark die Innovation und Wettbewerb in Computer Vision antrieb", nl: "Het bood een gestandaardiseerde benchmark die innovatie en competitie in computer vision aandreef" },
          { en: "It created the first computer", es: "Creó la primera computadora", de: "Es schuf den ersten Computer", nl: "Het creëerde de eerste computer" },
          { en: "It solved natural language processing", es: "Resolvió el procesamiento de lenguaje natural", de: "Es löste natürliche Sprachverarbeitung", nl: "Het loste natuurlijke taalverwerking op" },
          { en: "It invented the internet", es: "Inventó internet", de: "Es erfand das Internet", nl: "Het vond het internet uit" }
        ],
        correct: 0,
        explanation: {
          en: "ILSVRC became the premier computer vision competition with millions of labeled images across thousands of categories. It provided a rigorous testing ground that motivated algorithmic innovations, with AlexNet's 2012 victory marking the beginning of the deep learning era in computer vision.",
          es: "ILSVRC se convirtió en la competencia premier de visión por computadora con millones de imágenes etiquetadas en miles de categorías. Proporcionó un terreno de prueba riguroso que motivó innovaciones algorítmicas, con la victoria de AlexNet en 2012 marcando el comienzo de la era del aprendizaje profundo en visión por computadora.",
          de: "ILSVRC wurde zur führenden Computer Vision-Konkurrenz mit Millionen beschrifteter Bilder in Tausenden von Kategorien. Es bot ein rigoroses Testfeld das algorithmische Innovationen motivierte, wobei AlexNets Sieg 2012 den Beginn der Deep Learning-Ära in Computer Vision markierte.",
          nl: "ILSVRC werd de belangrijkste computer vision competitie met miljoenen gelabelde afbeeldingen in duizenden categorieën. Het bood een rigoureus testterrein dat algoritmische innovaties motiveerde, waarbij AlexNet's overwinning in 2012 het begin van het deep learning tijdperk in computer vision markeerde."
        }
      },
      {
        question: {
          en: "What was the significance of the development of DenseNet by Huang et al. in 2016?",
          es: "¿Cuál fue la importancia del desarrollo de DenseNet por Huang et al. en 2016?",
          de: "Was war die Bedeutung der Entwicklung von DenseNet durch Huang et al. 2016?",
          nl: "Wat was de betekenis van de ontwikkeling van DenseNet door Huang et al. in 2016?"
        },
        options: [
          { en: "It introduced dense connections where each layer connects to every subsequent layer", es: "Introdujo conexiones densas donde cada capa se conecta a cada capa subsecuente", de: "Es führte dichte Verbindungen ein bei denen jede Schicht sich mit jeder nachfolgenden Schicht verbindet", nl: "Het introduceerde dichte verbindingen waarbij elke laag verbindt met elke volgende laag" },
          { en: "It created the first mobile phone", es: "Creó el primer teléfono móvil", de: "Es schuf das erste Mobiltelefon", nl: "Het creëerde de eerste mobiele telefoon" },
          { en: "It solved quantum mechanics", es: "Resolvió la mecánica cuántica", de: "Es löste die Quantenmechanik", nl: "Het loste quantummechanica op" },
          { en: "It invented blockchain technology", es: "Inventó la tecnología blockchain", de: "Es erfand Blockchain-Technologie", nl: "Het vond blockchain technologie uit" }
        ],
        correct: 0,
        explanation: {
          en: "DenseNet connected each layer to every subsequent layer in a feed-forward fashion, creating extremely dense connectivity. This design improved gradient flow, reduced parameters through feature reuse, and achieved excellent performance with fewer parameters than traditional architectures.",
          es: "DenseNet conectó cada capa a cada capa subsecuente de manera feed-forward, creando conectividad extremadamente densa. Este diseño mejoró el flujo de gradientes, redujo parámetros a través de reutilización de características y logró excelente rendimiento con menos parámetros que arquitecturas tradicionales.",
          de: "DenseNet verband jede Schicht mit jeder nachfolgenden Schicht in feed-forward Weise und schuf extrem dichte Konnektivität. Dieses Design verbesserte Gradientenfluss, reduzierte Parameter durch Feature-Wiederverwendung und erreichte exzellente Leistung mit weniger Parametern als traditionelle Architekturen.",
          nl: "DenseNet verbond elke laag met elke volgende laag op een feed-forward manier, wat extreem dichte connectiviteit creëerde. Dit ontwerp verbeterde gradiënt flow, verminderde parameters door feature hergebruik en behaalde uitstekende prestaties met minder parameters dan traditionele architecturen."
        }
      },
      {
        question: {
          en: "What was the impact of transfer learning and pre-trained models in the deep learning revolution?",
          es: "¿Cuál fue el impacto del aprendizaje por transferencia y modelos pre-entrenados en la revolución del aprendizaje profundo?",
          de: "Was war die Auswirkung von Transfer Learning und vortrainierten Modellen in der Deep Learning-Revolution?",
          nl: "Wat was de impact van transfer learning en voorgetrainde modellen in de deep learning revolutie?"
        },
        options: [
          { en: "It enabled researchers and practitioners to leverage pre-trained networks for new tasks with limited data", es: "Permitió a investigadores y profesionales aprovechar redes pre-entrenadas para nuevas tareas con datos limitados", de: "Es ermöglichte Forschern und Praktikern vortrainierte Netzwerke für neue Aufgaben mit begrenzten Daten zu nutzen", nl: "Het stelde onderzoekers en praktijkers in staat voorgetrainde netwerken te benutten voor nieuwe taken met beperkte data" },
          { en: "It eliminated the need for computers", es: "Eliminó la necesidad de computadoras", de: "Es eliminierte die Notwendigkeit von Computern", nl: "Het elimineerde de behoefte aan computers" },
          { en: "It solved world hunger", es: "Resolvió el hambre mundial", de: "Es löste den Welthunger", nl: "Het loste wereldhonger op" },
          { en: "It created time machines", es: "Creó máquinas del tiempo", de: "Es schuf Zeitmaschinen", nl: "Het creëerde tijdmachines" }
        ],
        correct: 0,
        explanation: {
          en: "Transfer learning democratized deep learning by allowing practitioners to use models pre-trained on large datasets (like ImageNet) as starting points for new tasks. This approach dramatically reduced training time, data requirements, and computational resources needed for achieving good performance.",
          es: "El aprendizaje por transferencia democratizó el aprendizaje profundo permitiendo a profesionales usar modelos pre-entrenados en grandes conjuntos de datos (como ImageNet) como puntos de partida para nuevas tareas. Este enfoque redujo dramáticamente tiempo de entrenamiento, requisitos de datos y recursos computacionales necesarios para lograr buen rendimiento.",
          de: "Transfer Learning demokratisierte Deep Learning indem es Praktikern erlaubte auf großen Datensätzen (wie ImageNet) vortrainierte Modelle als Ausgangspunkte für neue Aufgaben zu verwenden. Dieser Ansatz reduzierte dramatisch Trainingszeit, Datenanforderungen und Rechenressourcen die für gute Leistung benötigt wurden.",
          nl: "Transfer learning democratiseerde deep learning door praktijkers toe te staan modellen voorgetraind op grote datasets (zoals ImageNet) te gebruiken als startpunten voor nieuwe taken. Deze benadering verminderde dramatisch trainingstijd, datavereisten en computationele bronnen nodig voor goede prestaties."
        }
      },
      {
        question: {
          en: "What was the role of deep learning frameworks like TensorFlow and PyTorch in the 2010s revolution?",
          es: "¿Cuál fue el papel de los marcos de aprendizaje profundo como TensorFlow y PyTorch en la revolución de los años 2010?",
          de: "Was war die Rolle von Deep Learning-Frameworks wie TensorFlow und PyTorch in der Revolution der 2010er?",
          nl: "Wat was de rol van deep learning frameworks zoals TensorFlow en PyTorch in de revolutie van de jaren 2010?"
        },
        options: [
          { en: "They democratized deep learning by providing accessible tools for building and training neural networks", es: "Democratizaron el aprendizaje profundo proporcionando herramientas accesibles para construir y entrenar redes neuronales", de: "Sie demokratisierten Deep Learning durch Bereitstellung zugänglicher Werkzeuge zum Bauen und Trainieren neuronaler Netzwerke", nl: "Ze democratiseerden deep learning door toegankelijke tools te bieden voor het bouwen en trainen van neurale netwerken" },
          { en: "They created the first computers", es: "Crearon las primeras computadoras", de: "Sie schufen die ersten Computer", nl: "Ze creëerden de eerste computers" },
          { en: "They solved climate change", es: "Resolvieron el cambio climático", de: "Sie lösten den Klimawandel", nl: "Ze losten klimaatverandering op" },
          { en: "They invented space travel", es: "Inventaron los viajes espaciales", de: "Sie erfanden Raumfahrt", nl: "Ze vonden ruimtereizen uit" }
        ],
        correct: 0,
        explanation: {
          en: "Deep learning frameworks provided high-level APIs, automatic differentiation, GPU support, and pre-built components that made deep learning accessible to a broader audience. TensorFlow (2015) and PyTorch (2016) became the dominant frameworks, accelerating research and deployment.",
          es: "Los marcos de aprendizaje profundo proporcionaron APIs de alto nivel, diferenciación automática, soporte GPU y componentes pre-construidos que hicieron accesible el aprendizaje profundo a una audiencia más amplia. TensorFlow (2015) y PyTorch (2016) se convirtieron en marcos dominantes, acelerando investigación y despliegue.",
          de: "Deep Learning-Frameworks boten high-level APIs, automatische Differentiation, GPU-Unterstützung und vorgefertigte Komponenten die Deep Learning einem breiteren Publikum zugänglich machten. TensorFlow (2015) und PyTorch (2016) wurden zu dominanten Frameworks und beschleunigten Forschung und Deployment.",
          nl: "Deep learning frameworks boden high-level APIs, automatische differentiatie, GPU ondersteuning en voorgebouwde componenten die deep learning toegankelijk maakten voor een breder publiek. TensorFlow (2015) en PyTorch (2016) werden de dominante frameworks, wat onderzoek en deployment versnelde."
        }
      },
      {
        question: {
          en: "What legacy did the deep learning breakthrough of the 2010s leave for modern AI?",
          es: "¿Qué legado dejó el avance del aprendizaje profundo de los años 2010 para la IA moderna?",
          de: "Welches Vermächtnis hinterließ der Deep Learning-Durchbruch der 2010er für moderne KI?",
          nl: "Welke erfenis liet de deep learning doorbraak van de jaren 2010 achter voor moderne AI?"
        },
        options: [
          { en: "It established deep neural networks as the dominant paradigm for AI across vision, language, and other domains", es: "Estableció las redes neuronales profundas como el paradigma dominante para IA en visión, lenguaje y otros dominios", de: "Es etablierte tiefe neuronale Netzwerke als dominantes Paradigma für KI in Vision, Sprache und anderen Bereichen", nl: "Het vestigde diepe neurale netwerken als het dominante paradigma voor AI in vision, taal en andere domeinen" },
          { en: "It proved that AI was impossible", es: "Probó que la IA era imposible", de: "Es bewies dass KI unmöglich war", nl: "Het bewees dat AI onmogelijk was" },
          { en: "It had no lasting impact", es: "No tuvo impacto duradero", de: "Es hatte keine dauerhafte Auswirkung", nl: "Het had geen blijvende impact" },
          { en: "It only improved computer graphics", es: "Solo mejoró los gráficos por computadora", de: "Es verbesserte nur Computergrafik", nl: "Het verbeterde alleen computergraphics" }
        ],
        correct: 0,
        explanation: {
          en: "The 2010s deep learning revolution fundamentally transformed AI, establishing neural networks as the dominant approach across computer vision, natural language processing, speech recognition, and many other domains. It created the foundation for modern AI systems including large language models, computer vision applications, and generative AI.",
          es: "La revolución del aprendizaje profundo de los años 2010 transformó fundamentalmente la IA, estableciendo las redes neuronales como el enfoque dominante en visión por computadora, procesamiento de lenguaje natural, reconocimiento de voz y muchos otros dominios. Creó la base para sistemas de IA modernos incluyendo modelos de lenguaje grandes, aplicaciones de visión por computadora e IA generativa.",
          de: "Die Deep Learning-Revolution der 2010er transformierte KI fundamental und etablierte neuronale Netzwerke als dominanten Ansatz in Computer Vision, natürlicher Sprachverarbeitung, Spracherkennung und vielen anderen Bereichen. Sie schuf die Grundlage für moderne KI-Systeme einschließlich großer Sprachmodelle, Computer Vision-Anwendungen und generativer KI.",
          nl: "De deep learning revolutie van de jaren 2010 transformeerde AI fundamenteel, vestigde neurale netwerken als de dominante benadering in computer vision, natuurlijke taalverwerking, spraakherkenning en vele andere domeinen. Het creëerde de basis voor moderne AI systemen inclusief grote taalmodellen, computer vision toepassingen en generatieve AI."
        }
      },
      {
        question: {
          en: "What was the significance of the ReLU (Rectified Linear Unit) activation function in the deep learning revolution?",
          es: "¿Cuál fue la importancia de la función de activación ReLU (Unidad Lineal Rectificada) en la revolución del aprendizaje profundo?",
          de: "Was war die Bedeutung der ReLU (Rectified Linear Unit) Aktivierungsfunktion in der Deep Learning-Revolution?",
          nl: "Wat was de betekenis van de ReLU (Rectified Linear Unit) activatiefunctie in de deep learning revolutie?"
        },
        options: [
          { en: "It solved the vanishing gradient problem and enabled training of much deeper networks", es: "Resolvió el problema del gradiente que desaparece y permitió entrenar redes mucho más profundas", de: "Es löste das Problem des verschwindenden Gradienten und ermöglichte das Training viel tieferer Netzwerke", nl: "Het loste het verdwijnende gradiënt probleem op en maakte training van veel diepere netwerken mogelijk" },
          { en: "It was the first activation function ever invented", es: "Fue la primera función de activación jamás inventada", de: "Es war die erste jemals erfundene Aktivierungsfunktion", nl: "Het was de eerste activatiefunctie ooit uitgevonden" },
          { en: "It created artificial consciousness", es: "Creó conciencia artificial", de: "Es schuf künstliches Bewusstsein", nl: "Het creëerde kunstmatig bewustzijn" },
          { en: "It solved natural language processing", es: "Resolvió el procesamiento de lenguaje natural", de: "Es löste natürliche Sprachverarbeitung", nl: "Het loste natuurlijke taalverwerking op" }
        ],
        correct: 0,
        explanation: {
          en: "ReLU activation (f(x) = max(0,x)) replaced sigmoid and tanh functions in deep networks because it doesn't saturate for positive values, maintaining gradients during backpropagation. This simple change was crucial for training much deeper networks effectively, contributing significantly to the deep learning revolution.",
          es: "La activación ReLU (f(x) = max(0,x)) reemplazó las funciones sigmoide y tanh en redes profundas porque no se satura para valores positivos, manteniendo gradientes durante la retropropagación. Este cambio simple fue crucial para entrenar redes mucho más profundas efectivamente, contribuyendo significativamente a la revolución del aprendizaje profundo.",
          de: "ReLU-Aktivierung (f(x) = max(0,x)) ersetzte Sigmoid- und Tanh-Funktionen in tiefen Netzwerken weil sie für positive Werte nicht sättigt und Gradienten während Backpropagation aufrechterhält. Diese einfache Änderung war entscheidend für effektives Training viel tieferer Netzwerke und trug erheblich zur Deep Learning-Revolution bei.",
          nl: "ReLU activatie (f(x) = max(0,x)) verving sigmoid en tanh functies in diepe netwerken omdat het niet verzadigt voor positieve waarden, waardoor gradiënten behouden blijven tijdens backpropagation. Deze eenvoudige verandering was cruciaal voor het effectief trainen van veel diepere netwerken, wat significant bijdroeg aan de deep learning revolutie."
        }
      },
      {
        question: {
          en: "What was dropout and why was it important for deep learning?",
          es: "¿Qué fue dropout y por qué fue importante para aprendizaje profundo?",
          de: "Was war Dropout und warum war es wichtig für Deep Learning?",
          nl: "Wat was dropout en waarom was het belangrijk voor deep learning?"
        },
        options: [
          { en: "A regularization technique randomly deactivating neurons during training to prevent overfitting", es: "Una técnica de regularización desactivando aleatoriamente neuronas durante entrenamiento para prevenir sobreajuste", de: "Eine Regularisierungstechnik die Neuronen zufällig während Training deaktiviert um Overfitting zu verhindern", nl: "Een regularisatie techniek die willekeurig neuronen deactiveert tijdens training om overfitting te voorkomen" },
          { en: "A database backup method", es: "Un método de respaldo de base de datos", de: "Eine Datenbank-Backup-Methode", nl: "Een database backup methode" },
          { en: "A programming language feature", es: "Una característica de lenguaje de programación", de: "Ein Programmiersprachen-Feature", nl: "Een programmeertaal functie" },
          { en: "A computer hardware component", es: "Un componente de hardware de computadora", de: "Eine Computer-Hardware-Komponente", nl: "Een computer hardware component" }
        ],
        correct: 0,
        explanation: {
          en: "Dropout, introduced by Hinton et al. in 2012, randomly drops neurons during training, forcing the network to learn redundant representations. This simple technique dramatically reduced overfitting in deep networks, enabling better generalization and becoming standard practice in deep learning architectures.",
          es: "Dropout, introducido por Hinton et al. en 2012, descarta aleatoriamente neuronas durante entrenamiento, forzando a la red a aprender representaciones redundantes. Esta técnica simple redujo dramáticamente el sobreajuste en redes profundas.",
          de: "Dropout, eingeführt von Hinton et al. 2012, lässt zufällig Neuronen während Training fallen und zwingt das Netzwerk redundante Repräsentationen zu lernen. Diese einfache Technik reduzierte Overfitting in tiefen Netzwerken dramatisch.",
          nl: "Dropout, geïntroduceerd door Hinton et al. in 2012, laat willekeurig neuronen vallen tijdens training, wat het netwerk dwingt redundante representaties te leren. Deze eenvoudige techniek verminderde overfitting in diepe netwerken dramatisch."
        }
      },
      {
        question: {
          en: "What was batch normalization's contribution to deep learning?",
          es: "¿Cuál fue la contribución de normalización por lotes al aprendizaje profundo?",
          de: "Was war Batch Normalization's Beitrag zu Deep Learning?",
          nl: "Wat was de bijdrage van batch normalisatie aan deep learning?"
        },
        options: [
          { en: "It stabilized training by normalizing layer inputs, enabling faster learning and deeper networks", es: "Estabilizó entrenamiento normalizando entradas de capa, permitiendo aprendizaje más rápido y redes más profundas", de: "Es stabilisierte Training durch Normalisierung von Layer-Eingaben und ermöglichte schnelleres Lernen und tiefere Netzwerke", nl: "Het stabiliseerde training door laag inputs te normaliseren, wat sneller leren en diepere netwerken mogelijk maakte" },
          { en: "It was a data storage technique", es: "Fue una técnica de almacenamiento de datos", de: "Es war eine Datenspeicherungstechnik", nl: "Het was een data opslag techniek" },
          { en: "It created new neural networks", es: "Creó nuevas redes neuronales", de: "Es schuf neue neuronale Netzwerke", nl: "Het creëerde nieuwe neurale netwerken" },
          { en: "It was a programming language", es: "Fue un lenguaje de programación", de: "Es war eine Programmiersprache", nl: "Het was een programmeertaal" }
        ],
        correct: 0,
        explanation: {
          en: "Batch normalization (2015) normalized activations at each layer, reducing internal covariate shift. This stabilized training, allowed higher learning rates, reduced sensitivity to initialization, and acted as regularization. It became essential for training very deep networks and is now standard in most architectures.",
          es: "La normalización por lotes (2015) normalizó activaciones en cada capa, reduciendo el cambio de covarianza interno. Esto estabilizó entrenamiento, permitió tasas de aprendizaje más altas y se volvió esencial para entrenar redes muy profundas.",
          de: "Batch-Normalisierung (2015) normalisierte Aktivierungen in jeder Schicht und reduzierte interne Kovarianzenverschiebung. Dies stabilisierte Training, erlaubte höhere Lernraten und wurde essentiell für Training sehr tiefer Netzwerke.",
          nl: "Batch normalisatie (2015) normaliseerde activaties bij elke laag, wat interne covariate shift verminderde. Dit stabiliseerde training, stond hogere leersnelheden toe en werd essentieel voor het trainen van zeer diepe netwerken."
        }
      },
      {
        question: {
          en: "What was Faster R-CNN's contribution to object detection?",
          es: "¿Cuál fue la contribución de Faster R-CNN a detección de objetos?",
          de: "Was war Faster R-CNN's Beitrag zur Objekterkennung?",
          nl: "Wat was de bijdrage van Faster R-CNN aan objectdetectie?"
        },
        options: [
          { en: "It introduced Region Proposal Networks enabling fast, accurate, end-to-end object detection", es: "Introdujo Redes de Propuesta de Región permitiendo detección de objetos rápida, precisa y de extremo a extremo", de: "Es führte Region Proposal Networks ein die schnelle, genaue End-to-End-Objekterkennung ermöglichten", nl: "Het introduceerde Region Proposal Networks die snelle, nauwkeurige, end-to-end objectdetectie mogelijk maakten" },
          { en: "It was a racing car", es: "Fue un auto de carreras", de: "Es war ein Rennwagen", nl: "Het was een raceauto" },
          { en: "It created social media", es: "Creó redes sociales", de: "Es schuf soziale Medien", nl: "Het creëerde sociale media" },
          { en: "It was a database system", es: "Fue un sistema de base de datos", de: "Es war ein Datenbanksystem", nl: "Het was een database systeem" }
        ],
        correct: 0,
        explanation: {
          en: "Faster R-CNN (2015) revolutionized object detection by replacing slow selective search with learned Region Proposal Networks (RPNs). This made the entire detection pipeline differentiable and trainable end-to-end, dramatically improving speed while maintaining high accuracy. It became the foundation for modern object detection systems.",
          es: "Faster R-CNN (2015) revolucionó detección de objetos reemplazando búsqueda selectiva lenta con Redes de Propuesta de Región aprendidas. Esto hizo diferenciable todo el pipeline de detección y entrenable de extremo a extremo.",
          de: "Faster R-CNN (2015) revolutionierte Objekterkennung durch Ersetzen langsamer selektiver Suche mit gelernten Region Proposal Networks. Dies machte die gesamte Erkennungspipeline differenzierbar und End-to-End trainierbar.",
          nl: "Faster R-CNN (2015) revolutioneerde objectdetectie door trage selectieve zoektocht te vervangen met geleerde Region Proposal Networks. Dit maakte de hele detectiepijplijn differentieerbaar en end-to-end trainbaar."
        }
      },
      {
        question: {
          en: "What was the significance of word2vec and word embeddings in NLP?",
          es: "¿Cuál fue la importancia de word2vec y embeddings de palabras en NLP?",
          de: "Was war die Bedeutung von word2vec und Wort-Embeddings in NLP?",
          nl: "Wat was de betekenis van word2vec en woord embeddings in NLP?"
        },
        options: [
          { en: "They represented words as dense vectors capturing semantic relationships and enabling neural NLP", es: "Representaron palabras como vectores densos capturando relaciones semánticas y permitiendo NLP neuronal", de: "Sie repräsentierten Wörter als dichte Vektoren die semantische Beziehungen erfassen und neuronales NLP ermöglichen", nl: "Ze representeerden woorden als dense vectors die semantische relaties vastleggen en neuraal NLP mogelijk maken" },
          { en: "They were programming languages", es: "Fueron lenguajes de programación", de: "Sie waren Programmiersprachen", nl: "Ze waren programmeertalen" },
          { en: "They created databases", es: "Crearon bases de datos", de: "Sie schufen Datenbanken", nl: "Ze creëerden databases" },
          { en: "They were computer hardware", es: "Fueron hardware de computadora", de: "Sie waren Computer-Hardware", nl: "Ze waren computer hardware" }
        ],
        correct: 0,
        explanation: {
          en: "Word2vec (2013) learned distributed representations where semantically similar words have similar vectors, enabling algebraic operations like king-man+woman≈queen. This revolutionized NLP by providing better input representations for neural networks than one-hot encoding, laying groundwork for modern language models.",
          es: "Word2vec (2013) aprendió representaciones distribuidas donde palabras semánticamente similares tienen vectores similares, permitiendo operaciones algebraicas como rey-hombre+mujer≈reina. Esto revolucionó NLP proporcionando mejores representaciones de entrada para redes neuronales.",
          de: "Word2vec (2013) lernte verteilte Repräsentationen wo semantisch ähnliche Wörter ähnliche Vektoren haben und algebraische Operationen wie König-Mann+Frau≈Königin ermöglichen. Dies revolutionierte NLP durch bessere Eingaberepräsentationen für neuronale Netzwerke.",
          nl: "Word2vec (2013) leerde gedistribueerde representaties waarbij semantisch vergelijkbare woorden vergelijkbare vectors hebben, wat algebraïsche operaties mogelijk maakt zoals koning-man+vrouw≈koningin. Dit revolutioneerde NLP door betere invoer representaties voor neurale netwerken."
        }
      },
      {
        question: {
          en: "What was DeepMind's AlphaGo achievement in 2016?",
          es: "¿Cuál fue el logro de AlphaGo de DeepMind en 2016?",
          de: "Was war DeepMinds AlphaGo Leistung 2016?",
          nl: "Wat was DeepMind's AlphaGo prestatie in 2016?"
        },
        options: [
          { en: "It defeated world champion Lee Sedol at Go using deep reinforcement learning", es: "Derrotó al campeón mundial Lee Sedol en Go usando aprendizaje por refuerzo profundo", de: "Es besiegte Weltmeister Lee Sedol in Go mit Deep Reinforcement Learning", nl: "Het versloeg wereldkampioen Lee Sedol in Go met behulp van deep reinforcement learning" },
          { en: "It was the first neural network", es: "Fue la primera red neuronal", de: "Es war das erste neuronale Netzwerk", nl: "Het was het eerste neurale netwerk" },
          { en: "It created the internet", es: "Creó internet", de: "Es schuf das Internet", nl: "Het creëerde het internet" },
          { en: "It was a programming language", es: "Fue un lenguaje de programación", de: "Es war eine Programmiersprache", nl: "Het was een programmeertaal" }
        ],
        correct: 0,
        explanation: {
          en: "AlphaGo's 4-1 victory over Lee Sedol shocked the world, as Go was considered too complex for computers due to its vast search space. AlphaGo combined deep CNNs for position evaluation, Monte Carlo tree search, and reinforcement learning, demonstrating that deep learning could master extremely complex strategic domains.",
          es: "La victoria 4-1 de AlphaGo sobre Lee Sedol impactó al mundo, ya que Go se consideraba demasiado complejo para computadoras. AlphaGo combinó CNN profundas para evaluación de posición, búsqueda de árbol Monte Carlo y aprendizaje por refuerzo.",
          de: "AlphaGos 4-1 Sieg über Lee Sedol schockierte die Welt, da Go als zu komplex für Computer galt. AlphaGo kombinierte tiefe CNNs für Positionsevaluierung, Monte Carlo Baumsuche und Reinforcement Learning.",
          nl: "AlphaGo's 4-1 overwinning op Lee Sedol schokte de wereld, omdat Go als te complex voor computers werd beschouwd. AlphaGo combineerde diepe CNNs voor positie evaluatie, Monte Carlo boom zoektocht en reinforcement learning."
        }
      },
      {
        question: {
          en: "What was VGGNet's contribution to deep learning architecture?",
          es: "¿Cuál fue la contribución de VGGNet a arquitectura de aprendizaje profundo?",
          de: "Was war VGGNets Beitrag zur Deep Learning-Architektur?",
          nl: "Wat was VGGNet's bijdrage aan deep learning architectuur?"
        },
        options: [
          { en: "It showed that very deep networks with small 3x3 filters could achieve excellent performance", es: "Mostró que redes muy profundas con filtros pequeños 3x3 podían lograr excelente rendimiento", de: "Es zeigte dass sehr tiefe Netzwerke mit kleinen 3x3 Filtern exzellente Leistung erreichen konnten", nl: "Het toonde aan dat zeer diepe netwerken met kleine 3x3 filters uitstekende prestaties konden bereiken" },
          { en: "It was a programming language", es: "Fue un lenguaje de programación", de: "Es war eine Programmiersprache", nl: "Het was een programmeertaal" },
          { en: "It created databases", es: "Creó bases de datos", de: "Es schuf Datenbanken", nl: "Het creëerde databases" },
          { en: "It was a computer game", es: "Fue un juego de computadora", de: "Es war ein Computerspiel", nl: "Het was een computerspel" }
        ],
        correct: 0,
        explanation: {
          en: "VGGNet (2014) demonstrated that network depth is crucial by stacking many convolutional layers with small 3x3 filters rather than using larger filters. Its simple, homogeneous architecture (16-19 layers) achieved excellent ImageNet performance and became widely adopted for transfer learning despite high computational cost.",
          es: "VGGNet (2014) demostró que la profundidad de red es crucial apilando muchas capas convolucionales con filtros pequeños 3x3. Su arquitectura simple y homogénea (16-19 capas) logró excelente rendimiento ImageNet y se adoptó ampliamente para aprendizaje por transferencia.",
          de: "VGGNet (2014) demonstrierte dass Netzwerktiefe entscheidend ist durch Stapeln vieler Convolutional Layers mit kleinen 3x3 Filtern. Seine einfache, homogene Architektur (16-19 Schichten) erreichte exzellente ImageNet-Leistung.",
          nl: "VGGNet (2014) toonde aan dat netwerkdiepte cruciaal is door veel convolutionele lagen te stapelen met kleine 3x3 filters. Zijn eenvoudige, homogene architectuur (16-19 lagen) bereikte uitstekende ImageNet prestaties."
        }
      },
      {
        question: {
          en: "What was the significance of Xavier/He initialization methods?",
          es: "¿Cuál fue la importancia de los métodos de inicialización Xavier/He?",
          de: "Was war die Bedeutung der Xavier/He Initialisierungsmethoden?",
          nl: "Wat was de betekenis van Xavier/He initialisatie methoden?"
        },
        options: [
          { en: "They provided proper weight initialization preventing vanishing/exploding gradients in deep networks", es: "Proporcionaron inicialización adecuada de pesos previniendo gradientes que desaparecen/explotan en redes profundas", de: "Sie boten angemessene Gewichtsinitialisierung die verschwindende/explodierende Gradienten in tiefen Netzwerken verhinderte", nl: "Ze boden goede gewichtsinitialisatie die verdwijnende/exploderende gradiënten in diepe netwerken voorkwam" },
          { en: "They were programming languages", es: "Fueron lenguajes de programación", de: "Sie waren Programmiersprachen", nl: "Ze waren programmeertalen" },
          { en: "They created social media", es: "Crearon redes sociales", de: "Sie schufen soziale Medien", nl: "Ze creëerden sociale media" },
          { en: "They were database systems", es: "Fueron sistemas de base de datos", de: "Sie waren Datenbanksysteme", nl: "Ze waren database systemen" }
        ],
        correct: 0,
        explanation: {
          en: "Xavier (Glorot) initialization (2010) and He initialization (2015) set initial weights based on layer sizes to maintain variance of activations and gradients across layers. This solved training instability in deep networks and became standard practice, with He init especially important for ReLU activations.",
          es: "La inicialización Xavier (Glorot) (2010) y He (2015) establecieron pesos iniciales basados en tamaños de capa para mantener varianza de activaciones y gradientes. Esto resolvió inestabilidad de entrenamiento en redes profundas y se volvió práctica estándar.",
          de: "Xavier (Glorot) Initialisierung (2010) und He Initialisierung (2015) setzten initiale Gewichte basierend auf Layer-Größen um Varianz von Aktivierungen und Gradienten zu erhalten. Dies löste Trainingsinstabilität in tiefen Netzwerken.",
          nl: "Xavier (Glorot) initialisatie (2010) en He initialisatie (2015) stelden initiële gewichten in gebaseerd op laaggroottes om variantie van activaties en gradiënten te behouden. Dit loste trainingsinstabiliteit in diepe netwerken op."
        }
      },
      {
        question: {
          en: "What was the impact of semantic segmentation networks like FCN and U-Net?",
          es: "¿Cuál fue el impacto de redes de segmentación semántica como FCN y U-Net?",
          de: "Was war die Auswirkung von semantischen Segmentierungsnetzwerken wie FCN und U-Net?",
          nl: "Wat was de impact van semantische segmentatie netwerken zoals FCN en U-Net?"
        },
        options: [
          { en: "They enabled pixel-level image understanding for medical imaging, autonomous driving, and scene understanding", es: "Permitieron comprensión de imagen a nivel de píxel para imágenes médicas, conducción autónoma y comprensión de escenas", de: "Sie ermöglichten Bildverständnis auf Pixelebene für medizinische Bildgebung, autonomes Fahren und Szenenverständnis", nl: "Ze maakten beeldinterpretatie op pixelniveau mogelijk voor medische beeldvorming, autonoom rijden en scène begrip" },
          { en: "They were video game consoles", es: "Fueron consolas de videojuegos", de: "Sie waren Videospielkonsolen", nl: "Ze waren videogame consoles" },
          { en: "They created cryptocurrencies", es: "Crearon criptomonedas", de: "Sie schufen Kryptowährungen", nl: "Ze creëerden cryptocurrencies" },
          { en: "They were programming languages", es: "Fueron lenguajes de programación", de: "Sie waren Programmiersprachen", nl: "Ze waren programmeertalen" }
        ],
        correct: 0,
        explanation: {
          en: "Fully Convolutional Networks (FCN, 2015) and U-Net (2015) enabled dense prediction by classifying every pixel. U-Net's encoder-decoder architecture with skip connections became especially influential in medical image segmentation. These architectures enabled applications requiring detailed pixel-level understanding of images.",
          es: "Las Redes Completamente Convolucionales (FCN, 2015) y U-Net (2015) permitieron predicción densa clasificando cada píxel. La arquitectura encoder-decoder de U-Net con conexiones de salto se volvió especialmente influyente en segmentación de imágenes médicas.",
          de: "Fully Convolutional Networks (FCN, 2015) und U-Net (2015) ermöglichten dichte Vorhersage durch Klassifizierung jedes Pixels. U-Nets Encoder-Decoder-Architektur mit Skip-Verbindungen wurde besonders einflussreich in medizinischer Bildsegmentierung.",
          nl: "Fully Convolutional Networks (FCN, 2015) en U-Net (2015) maakten dense voorspelling mogelijk door elk pixel te classificeren. U-Net's encoder-decoder architectuur met skip connecties werd vooral invloedrijk in medische beeldsegmentatie."
        }
      },
      {
        question: {
          en: "What was the contribution of Adam optimizer to deep learning?",
          es: "¿Cuál fue la contribución del optimizador Adam al aprendizaje profundo?",
          de: "Was war der Beitrag des Adam-Optimierers zu Deep Learning?",
          nl: "Wat was de bijdrage van de Adam optimizer aan deep learning?"
        },
        options: [
          { en: "It combined momentum and adaptive learning rates, becoming the default optimizer for many applications", es: "Combinó momentum y tasas de aprendizaje adaptativas, convirtiéndose en el optimizador predeterminado para muchas aplicaciones", de: "Es kombinierte Momentum und adaptive Lernraten und wurde zum Standard-Optimierer für viele Anwendungen", nl: "Het combineerde momentum en adaptieve leersnelheden, en werd de standaard optimizer voor veel toepassingen" },
          { en: "It was a programming language", es: "Fue un lenguaje de programación", de: "Es war eine Programmiersprache", nl: "Het was een programmeertaal" },
          { en: "It created neural networks", es: "Creó redes neuronales", de: "Es schuf neuronale Netzwerke", nl: "Het creëerde neurale netwerken" },
          { en: "It was a database system", es: "Fue un sistema de base de datos", de: "Es war ein Datenbanksystem", nl: "Het was een database systeem" }
        ],
        correct: 0,
        explanation: {
          en: "Adam optimizer (2014) combined ideas from RMSprop and momentum, maintaining per-parameter adaptive learning rates and momentum terms. It required minimal tuning, worked well across diverse problems, and became extremely popular in deep learning, often serving as the default optimizer for neural network training.",
          es: "El optimizador Adam (2014) combinó ideas de RMSprop y momentum, manteniendo tasas de aprendizaje adaptativas por parámetro y términos de momentum. Requirió ajuste mínimo, funcionó bien en problemas diversos y se volvió extremadamente popular en aprendizaje profundo.",
          de: "Adam-Optimierer (2014) kombinierte Ideen von RMSprop und Momentum und behielt parameter-spezifische adaptive Lernraten und Momentum-Terme bei. Er benötigte minimales Tuning, funktionierte gut über diverse Probleme und wurde extrem populär in Deep Learning.",
          nl: "Adam optimizer (2014) combineerde ideeën van RMSprop en momentum, waarbij per-parameter adaptieve leersnelheden en momentum termen behouden bleven. Het vereiste minimale afstemming, werkte goed over diverse problemen en werd extreem populair in deep learning."
        }
      },
      {
        question: {
          en: "What was the significance of data augmentation in deep learning's success?",
          es: "¿Cuál fue la importancia del aumento de datos en el éxito del aprendizaje profundo?",
          de: "Was war die Bedeutung von Datenaugmentation für den Erfolg des Deep Learning?",
          nl: "Wat was de betekenis van data augmentatie in het succes van deep learning?"
        },
        options: [
          { en: "It artificially expanded training datasets through transformations, reducing overfitting and improving generalization", es: "Expandió artificialmente conjuntos de datos de entrenamiento mediante transformaciones, reduciendo sobreajuste y mejorando generalización", de: "Es erweiterte künstlich Trainingsdatensätze durch Transformationen, reduzierte Overfitting und verbesserte Generalisierung", nl: "Het breidde kunstmatig trainings datasets uit door transformaties, wat overfitting verminderde en generalisatie verbeterde" },
          { en: "It was a database management technique", es: "Fue una técnica de gestión de base de datos", de: "Es war eine Datenbankverwaltungstechnik", nl: "Het was een database beheertechniek" },
          { en: "It created programming languages", es: "Creó lenguajes de programación", de: "Es schuf Programmiersprachen", nl: "Het creëerde programmeertalen" },
          { en: "It was a computer hardware improvement", es: "Fue una mejora de hardware de computadora", de: "Es war eine Computer-Hardware-Verbesserung", nl: "Het was een computer hardware verbetering" }
        ],
        correct: 0,
        explanation: {
          en: "Data augmentation (random crops, flips, rotations, color jittering) became crucial for deep learning success by artificially increasing training data diversity. AlexNet extensively used augmentation, and it became standard practice. By exposing networks to varied versions of training examples, it improved robustness and generalization without collecting more data.",
          es: "El aumento de datos (recortes aleatorios, volteos, rotaciones, variación de color) se volvió crucial para el éxito del aprendizaje profundo aumentando artificialmente la diversidad de datos de entrenamiento. AlexNet usó extensivamente aumento y se convirtió en práctica estándar.",
          de: "Datenaugmentation (zufällige Zuschnitte, Spiegelungen, Rotationen, Farbvariationen) wurde entscheidend für Deep Learning-Erfolg durch künstliche Erhöhung der Trainingsdaten-Diversität. AlexNet nutzte extensiv Augmentation und es wurde Standardpraxis.",
          nl: "Data augmentatie (willekeurige uitsnedes, spiegelingen, rotaties, kleurvariaties) werd cruciaal voor deep learning succes door kunstmatig trainingsdatadiversiteit te verhogen. AlexNet gebruikte uitgebreid augmentatie en het werd standaardpraktijk."
        }
      },
      {
        question: {
          en: "What was the role of GPUs in enabling the deep learning revolution?",
          es: "¿Cuál fue el papel de las GPU en habilitar la revolución del aprendizaje profundo?",
          de: "Was war die Rolle von GPUs bei der Ermöglichung der Deep Learning-Revolution?",
          nl: "Wat was de rol van GPUs bij het mogelijk maken van de deep learning revolutie?"
        },
        options: [
          { en: "They provided massive parallel processing enabling training of large neural networks in reasonable time", es: "Proporcionaron procesamiento masivamente paralelo permitiendo entrenar grandes redes neuronales en tiempo razonable", de: "Sie boten massiv parallele Verarbeitung die Training großer neuronaler Netzwerke in angemessener Zeit ermöglichte", nl: "Ze boden massaal parallelle verwerking die training van grote neurale netwerken in redelijke tijd mogelijk maakte" },
          { en: "They created artificial consciousness", es: "Crearon conciencia artificial", de: "Sie schufen künstliches Bewusstsein", nl: "Ze creëerden kunstmatig bewustzijn" },
          { en: "They invented neural networks", es: "Inventaron redes neuronales", de: "Sie erfanden neuronale Netzwerke", nl: "Ze vonden neurale netwerken uit" },
          { en: "They were programming languages", es: "Fueron lenguajes de programación", de: "Sie waren Programmiersprachen", nl: "Ze waren programmeertalen" }
        ],
        correct: 0,
        explanation: {
          en: "GPUs revolutionized deep learning by providing massive parallelization perfect for matrix operations in neural networks. AlexNet's use of GPUs enabled 10-50x speedups over CPUs. NVIDIA's CUDA and later cuDNN libraries made GPU programming accessible, allowing researchers to train deeper networks on larger datasets, fundamentally enabling the deep learning revolution.",
          es: "Las GPU revolucionaron el aprendizaje profundo proporcionando paralelización masiva perfecta para operaciones matriciales en redes neuronales. El uso de GPU por AlexNet permitió aceleraciones de 10-50x sobre CPU. Las bibliotecas CUDA y cuDNN de NVIDIA hicieron accesible la programación GPU.",
          de: "GPUs revolutionierten Deep Learning durch massive Parallelisierung perfekt für Matrixoperationen in neuronalen Netzwerken. AlexNets GPU-Nutzung ermöglichte 10-50x Beschleunigungen über CPUs. NVIDIAs CUDA und später cuDNN-Bibliotheken machten GPU-Programmierung zugänglich.",
          nl: "GPUs revolutioneerden deep learning door massale parallellisatie perfect voor matrix operaties in neurale netwerken te bieden. AlexNet's gebruik van GPUs maakte 10-50x snelheidsverbeteringen over CPUs mogelijk. NVIDIA's CUDA en later cuDNN bibliotheken maakten GPU programmering toegankelijk."
        }
      },
      {
        question: {
          en: "What was the impact of ImageNet Large Scale Visual Recognition Challenge (ILSVRC)?",
          es: "¿Cuál fue el impacto del Desafío de Reconocimiento Visual a Gran Escala ImageNet (ILSVRC)?",
          de: "Was war die Auswirkung der ImageNet Large Scale Visual Recognition Challenge (ILSVRC)?",
          nl: "Wat was de impact van de ImageNet Large Scale Visual Recognition Challenge (ILSVRC)?"
        },
        options: [
          { en: "It provided standardized benchmark driving computer vision progress and deep learning advances", es: "Proporcionó benchmark estandarizado impulsando progreso de visión por computadora y avances de aprendizaje profundo", de: "Es bot standardisiertes Benchmark das Computer Vision-Fortschritt und Deep Learning-Fortschritte antrieb", nl: "Het bood gestandaardiseerde benchmark die computer vision vooruitgang en deep learning vooruitgang stimuleerde" },
          { en: "It was a video game tournament", es: "Fue un torneo de videojuegos", de: "Es war ein Videospiel-Turnier", nl: "Het was een videogame toernooi" },
          { en: "It created social media", es: "Creó redes sociales", de: "Es schuf soziale Medien", nl: "Het creëerde sociale media" },
          { en: "It was a programming competition", es: "Fue una competencia de programación", de: "Es war ein Programmierwettbewerb", nl: "Het was een programmeer competitie" }
        ],
        correct: 0,
        explanation: {
          en: "ILSVRC (2010-2017) provided a standardized benchmark with 1.2M training images across 1000 categories. AlexNet's dramatic 2012 victory launched the deep learning era. Annual competitions drove rapid progress: error rates dropped from 28% (2010) to 2.3% (2017, below human performance), spurring innovations in architectures, optimization, and training techniques.",
          es: "ILSVRC (2010-2017) proporcionó benchmark estandarizado con 1.2M imágenes de entrenamiento en 1000 categorías. La victoria dramática de AlexNet en 2012 lanzó la era del aprendizaje profundo. Las competencias anuales impulsaron progreso rápido: tasas de error cayeron de 28% (2010) a 2.3% (2017).",
          de: "ILSVRC (2010-2017) bot standardisiertes Benchmark mit 1,2M Trainingsbildern über 1000 Kategorien. AlexNets dramatischer 2012-Sieg startete die Deep Learning-Ära. Jährliche Wettbewerbe trieben raschen Fortschritt an: Fehlerraten fielen von 28% (2010) auf 2,3% (2017).",
          nl: "ILSVRC (2010-2017) bood gestandaardiseerde benchmark met 1,2M trainingsafbeeldingen over 1000 categorieën. AlexNet's dramatische overwinning in 2012 lanceerde het deep learning tijdperk. Jaarlijkse competities dreven snelle vooruitgang aan: foutpercentages daalden van 28% (2010) naar 2,3% (2017)."
        }
      },
      {
        question: {
          en: "What was the contribution of transfer learning to deep learning's practical success?",
          es: "¿Cuál fue la contribución del aprendizaje por transferencia al éxito práctico del aprendizaje profundo?",
          de: "Was war der Beitrag von Transfer Learning zum praktischen Erfolg des Deep Learning?",
          nl: "Wat was de bijdrage van transfer learning aan het praktische succes van deep learning?"
        },
        options: [
          { en: "It enabled reusing pretrained models for new tasks with limited data, democratizing deep learning", es: "Permitió reutilizar modelos preentrenados para nuevas tareas con datos limitados, democratizando aprendizaje profundo", de: "Es ermöglichte Wiederverwendung vortrainierter Modelle für neue Aufgaben mit begrenzten Daten und demokratisierte Deep Learning", nl: "Het maakte hergebruik van voorgetrainde modellen voor nieuwe taken met beperkte data mogelijk, wat deep learning democratiseerde" },
          { en: "It was a file transfer protocol", es: "Fue un protocolo de transferencia de archivos", de: "Es war ein Dateiübertragungsprotokoll", nl: "Het was een bestandsoverdracht protocol" },
          { en: "It created social media", es: "Creó redes sociales", de: "Es schuf soziale Medien", nl: "Het creëerde sociale media" },
          { en: "It was a programming language", es: "Fue un lenguaje de programación", de: "Es war eine Programmiersprache", nl: "Het was een programmeertaal" }
        ],
        correct: 0,
        explanation: {
          en: "Transfer learning allowed practitioners to use ImageNet-pretrained models (VGG, ResNet, etc.) as starting points for custom tasks, fine-tuning on smaller domain-specific datasets. This dramatically reduced data and compute requirements, enabling deep learning applications in fields lacking massive labeled datasets and making the technology accessible to broader audiences.",
          es: "El aprendizaje por transferencia permitió a practicantes usar modelos preentrenados en ImageNet como puntos de partida para tareas personalizadas, ajustando en conjuntos de datos más pequeños. Esto redujo dramáticamente requisitos de datos y cómputo.",
          de: "Transfer Learning erlaubte Praktikern ImageNet-vortrainierte Modelle als Ausgangspunkte für individuelle Aufgaben zu nutzen und auf kleineren domänenspezifischen Datensätzen feinabzustimmen. Dies reduzierte Daten- und Rechenanforderungen dramatisch.",
          nl: "Transfer learning stelde praktijkmensen in staat om ImageNet-voorgetrainde modellen te gebruiken als startpunten voor aangepaste taken, waarbij ze fijnafgestemd werden op kleinere domein-specifieke datasets. Dit verminderde data- en rekenbehoeften dramatisch."
        }
      },
      {
        question: {
          en: "What was Inception (GoogLeNet) architecture's innovation?",
          es: "¿Cuál fue la innovación de la arquitectura Inception (GoogLeNet)?",
          de: "Was war die Innovation der Inception (GoogLeNet) Architektur?",
          nl: "Wat was de innovatie van de Inception (GoogLeNet) architectuur?"
        },
        options: [
          { en: "It used multi-scale inception modules processing inputs at multiple resolutions simultaneously", es: "Usó módulos inception multi-escala procesando entradas en múltiples resoluciones simultáneamente", de: "Es nutzte Multi-Scale Inception-Module die Eingaben auf mehreren Auflösungen gleichzeitig verarbeiteten", nl: "Het gebruikte multi-schaal inception modules die invoer op meerdere resoluties tegelijkertijd verwerkten" },
          { en: "It was a movie production technique", es: "Fue una técnica de producción cinematográfica", de: "Es war eine Filmproduktions-Technik", nl: "Het was een filmproductie techniek" },
          { en: "It created programming languages", es: "Creó lenguajes de programación", de: "Es schuf Programmiersprachen", nl: "Het creëerde programmeertalen" },
          { en: "It was a database system", es: "Fue un sistema de base de datos", de: "Es war ein Datenbanksystem", nl: "Het was een database systeem" }
        ],
        correct: 0,
        explanation: {
          en: "GoogLeNet/Inception (2014) introduced inception modules that applied convolutions of different sizes (1x1, 3x3, 5x5) in parallel, allowing the network to capture features at multiple scales efficiently. This design achieved excellent performance while being computationally efficient, winning ILSVRC 2014 and inspiring many subsequent architectures.",
          es: "GoogLeNet/Inception (2014) introdujo módulos inception que aplicaron convoluciones de diferentes tamaños en paralelo, permitiendo a la red capturar características en múltiples escalas eficientemente. Este diseño logró excelente rendimiento siendo computacionalmente eficiente.",
          de: "GoogLeNet/Inception (2014) führte Inception-Module ein die Faltungen verschiedener Größen parallel anwendeten und dem Netzwerk ermöglichten Features auf mehreren Skalen effizient zu erfassen. Dieses Design erreichte exzellente Leistung bei Recheneffizienz.",
          nl: "GoogLeNet/Inception (2014) introduceerde inception modules die convoluties van verschillende groottes parallel toepasten, waardoor het netwerk features op meerdere schalen efficiënt kon vastleggen. Dit ontwerp bereikte uitstekende prestaties met computationele efficiëntie."
        }
      },
      {
        question: {
          en: "What was the significance of residual connections (skip connections) beyond ResNet?",
          es: "¿Cuál fue la importancia de conexiones residuales más allá de ResNet?",
          de: "Was war die Bedeutung von Residualverbindungen über ResNet hinaus?",
          nl: "Wat was de betekenis van residuele connecties (skip connecties) verder dan ResNet?"
        },
        options: [
          { en: "They became fundamental architectural component used in transformers, U-Net, and many modern architectures", es: "Se convirtieron en componente arquitectónico fundamental usado en transformers, U-Net y muchas arquitecturas modernas", de: "Sie wurden fundamentale architektonische Komponente in Transformers, U-Net und vielen modernen Architekturen", nl: "Ze werden fundamenteel architecturaal component gebruikt in transformers, U-Net en vele moderne architecturen" },
          { en: "They were only used in ResNet", es: "Solo se usaron en ResNet", de: "Sie wurden nur in ResNet verwendet", nl: "Ze werden alleen in ResNet gebruikt" },
          { en: "They created social media", es: "Crearon redes sociales", de: "Sie schufen soziale Medien", nl: "Ze creëerden sociale media" },
          { en: "They were programming tools", es: "Fueron herramientas de programación", de: "Sie waren Programmierwerkzeuge", nl: "Ze waren programmeertools" }
        ],
        correct: 0,
        explanation: {
          en: "Skip connections proved broadly useful beyond ResNet. U-Net used them for medical segmentation, DenseNet connected all layers, and transformers employ residual connections around attention layers. The principle of adding identity shortcuts to facilitate gradient flow and feature reuse became a fundamental design pattern in modern deep architectures.",
          es: "Las conexiones de salto demostraron ser ampliamente útiles más allá de ResNet. U-Net las usó para segmentación médica, DenseNet conectó todas las capas, y los transformers emplean conexiones residuales alrededor de capas de atención. El principio se volvió patrón de diseño fundamental.",
          de: "Skip-Verbindungen erwiesen sich über ResNet hinaus als breit nützlich. U-Net nutzte sie für medizinische Segmentierung, DenseNet verband alle Schichten, und Transformer verwenden Residualverbindungen um Attention-Layer. Das Prinzip wurde fundamentales Designmuster.",
          nl: "Skip connecties bleken breed nuttig voorbij ResNet. U-Net gebruikte ze voor medische segmentatie, DenseNet verbond alle lagen, en transformers gebruiken residuele connecties rond attention lagen. Het principe werd een fundamenteel ontwerppatroon."
        }
      },
      {
        question: {
          en: "What was the role of large labeled datasets in the deep learning revolution?",
          es: "¿Cuál fue el papel de grandes conjuntos de datos etiquetados en la revolución del aprendizaje profundo?",
          de: "Was war die Rolle großer gelabelter Datensätze in der Deep Learning-Revolution?",
          nl: "Wat was de rol van grote gelabelde datasets in de deep learning revolutie?"
        },
        options: [
          { en: "They provided training data needed for deep networks to learn complex representations and generalize well", es: "Proporcionaron datos de entrenamiento necesarios para que redes profundas aprendieran representaciones complejas y generalizaran bien", de: "Sie boten Trainingsdaten die tiefe Netzwerke brauchten um komplexe Repräsentationen zu lernen und gut zu generalisieren", nl: "Ze boden trainingsdata die diepe netwerken nodig hadden om complexe representaties te leren en goed te generaliseren" },
          { en: "They were storage systems", es: "Fueron sistemas de almacenamiento", de: "Sie waren Speichersysteme", nl: "Ze waren opslagsystemen" },
          { en: "They created programming languages", es: "Crearon lenguajes de programación", de: "Sie schufen Programmiersprachen", nl: "Ze creëerden programmeertalen" },
          { en: "They were computer hardware", es: "Fueron hardware de computadora", de: "Sie waren Computer-Hardware", nl: "Ze waren computer hardware" }
        ],
        correct: 0,
        explanation: {
          en: "Large labeled datasets (ImageNet: 1.2M images, MS COCO, etc.) were crucial for deep learning success. Deep networks' massive parameter counts required enormous training data to avoid overfitting. Creating, curating, and labeling these datasets involved massive human effort but enabled training networks that could learn hierarchical features and generalize to real-world scenarios.",
          es: "Grandes conjuntos de datos etiquetados (ImageNet: 1.2M imágenes, MS COCO, etc.) fueron cruciales para el éxito del aprendizaje profundo. Los enormes recuentos de parámetros de redes profundas requerían datos de entrenamiento enormes para evitar sobreajuste.",
          de: "Große gelabelte Datensätze (ImageNet: 1,2M Bilder, MS COCO, etc.) waren entscheidend für Deep Learning-Erfolg. Die massiven Parameterzahlen tiefer Netzwerke erforderten enorme Trainingsdaten um Overfitting zu vermeiden.",
          nl: "Grote gelabelde datasets (ImageNet: 1,2M afbeeldingen, MS COCO, etc.) waren cruciaal voor deep learning succes. De massale parameter aantallen van diepe netwerken vereisten enorme trainingsdata om overfitting te voorkomen."
        }
      },
      {
        question: {
          en: "What was DenseNet's architectural contribution?",
          es: "¿Cuál fue la contribución arquitectónica de DenseNet?",
          de: "Was war DenseNets architektonischer Beitrag?",
          nl: "Wat was DenseNet's architectonische bijdrage?"
        },
        options: [
          { en: "It connected each layer to all subsequent layers, maximizing feature reuse and gradient flow", es: "Conectó cada capa con todas las capas subsiguientes, maximizando reutilización de características y flujo de gradiente", de: "Es verband jede Schicht mit allen nachfolgenden Schichten und maximierte Feature-Wiederverwendung und Gradientenfluss", nl: "Het verbond elke laag met alle volgende lagen, wat feature hergebruik en gradiënt flow maximaliseerde" },
          { en: "It was a compression algorithm", es: "Fue un algoritmo de compresión", de: "Es war ein Kompressionsalgorithmus", nl: "Het was een compressie algoritme" },
          { en: "It created databases", es: "Creó bases de datos", de: "Es schuf Datenbanken", nl: "Het creëerde databases" },
          { en: "It was a programming paradigm", es: "Fue un paradigma de programación", de: "Es war ein Programmierparadigma", nl: "Het was een programmeerparadigma" }
        ],
        correct: 0,
        explanation: {
          en: "DenseNet (2017) took skip connections to the extreme: each layer received inputs from all previous layers and passed its output to all subsequent layers. This dense connectivity pattern improved feature propagation, encouraged feature reuse, and reduced parameters while achieving excellent performance, though at higher memory cost.",
          es: "DenseNet (2017) llevó las conexiones de salto al extremo: cada capa recibió entradas de todas las capas anteriores. Este patrón de conectividad densa mejoró propagación de características, fomentó reutilización de características y redujo parámetros logrando excelente rendimiento.",
          de: "DenseNet (2017) trieb Skip-Verbindungen zum Extrem: jede Schicht erhielt Eingaben von allen vorherigen Schichten. Dieses dichte Konnektivitätsmuster verbesserte Feature-Propagierung, förderte Feature-Wiederverwendung und reduzierte Parameter bei exzellenter Leistung.",
          nl: "DenseNet (2017) dreef skip connecties naar het uiterste: elke laag ontving invoer van alle vorige lagen. Dit dichte connectiviteitspatroon verbeterde feature propagatie, moedigde feature hergebruik aan en verminderde parameters met uitstekende prestaties."
        }
      },
      {
        question: {
          en: "What was the impact of MobileNet and efficient architectures?",
          es: "¿Cuál fue el impacto de MobileNet y arquitecturas eficientes?",
          de: "Was war die Auswirkung von MobileNet und effizienten Architekturen?",
          nl: "Wat was de impact van MobileNet en efficiënte architecturen?"
        },
        options: [
          { en: "They enabled deep learning on mobile devices and edge computing through depthwise separable convolutions", es: "Permitieron aprendizaje profundo en dispositivos móviles y edge computing mediante convoluciones separables en profundidad", de: "Sie ermöglichten Deep Learning auf Mobilgeräten und Edge Computing durch depthwise separable Faltungen", nl: "Ze maakten deep learning op mobiele apparaten en edge computing mogelijk door depthwise separable convoluties" },
          { en: "They created mobile phones", es: "Crearon teléfonos móviles", de: "Sie schufen Mobiltelefone", nl: "Ze creëerden mobiele telefoons" },
          { en: "They were social media apps", es: "Fueron aplicaciones de redes sociales", de: "Sie waren Social-Media-Apps", nl: "Ze waren sociale media apps" },
          { en: "They invented databases", es: "Inventaron bases de datos", de: "Sie erfanden Datenbanken", nl: "Ze vonden databases uit" }
        ],
        correct: 0,
        explanation: {
          en: "MobileNet (2017) and similar efficient architectures (ShuffleNet, EfficientNet) used depthwise separable convolutions and neural architecture search to dramatically reduce computation while maintaining accuracy. This enabled on-device inference for smartphones and IoT devices, expanding deep learning's applicability beyond cloud servers to edge deployment.",
          es: "MobileNet (2017) y arquitecturas eficientes similares usaron convoluciones separables en profundidad y búsqueda de arquitectura neuronal para reducir dramáticamente el cómputo manteniendo precisión. Esto permitió inferencia en dispositivo para smartphones y dispositivos IoT.",
          de: "MobileNet (2017) und ähnliche effiziente Architekturen nutzten depthwise separable Faltungen und Neural Architecture Search um Berechnung dramatisch zu reduzieren bei erhaltener Genauigkeit. Dies ermöglichte On-Device-Inferenz für Smartphones und IoT-Geräte.",
          nl: "MobileNet (2017) en vergelijkbare efficiënte architecturen gebruikten depthwise separable convoluties en neural architecture search om berekening dramatisch te verminderen met behoud van nauwkeurigheid. Dit maakte on-device inferentie voor smartphones en IoT apparaten mogelijk."
        }
      },
      {
        question: {
          en: "What was the significance of neural architecture search (NAS)?",
          es: "¿Cuál fue la importancia de la búsqueda de arquitectura neuronal (NAS)?",
          de: "Was war die Bedeutung von Neural Architecture Search (NAS)?",
          nl: "Wat was de betekenis van neural architecture search (NAS)?"
        },
        options: [
          { en: "It automated architecture design using ML to discover architectures, sometimes outperforming human designs", es: "Automatizó diseño de arquitectura usando ML para descubrir arquitecturas, a veces superando diseños humanos", de: "Es automatisierte Architektur-Design mit ML um Architekturen zu entdecken, manchmal besser als menschliche Designs", nl: "Het automatiseerde architectuurontwerp met ML om architecturen te ontdekken, soms beter dan menselijke ontwerpen" },
          { en: "It was a web search engine", es: "Fue un motor de búsqueda web", de: "Es war eine Web-Suchmaschine", nl: "Het was een web zoekmachine" },
          { en: "It created databases", es: "Creó bases de datos", de: "Es schuf Datenbanken", nl: "Het creëerde databases" },
          { en: "It was a programming tool", es: "Fue una herramienta de programación", de: "Es war ein Programmierwerkzeug", nl: "Het was een programmeertool" }
        ],
        correct: 0,
        explanation: {
          en: "NAS (2017+) used reinforcement learning, evolutionary algorithms, or gradient-based methods to automatically search for optimal network architectures. While computationally expensive initially, NAS discovered architectures like NASNet and EfficientNet that matched or exceeded human-designed networks, opening possibilities for automated ML system design.",
          es: "NAS (2017+) usó aprendizaje por refuerzo, algoritmos evolutivos o métodos basados en gradiente para buscar automáticamente arquitecturas de red óptimas. Aunque inicialmente costoso computacionalmente, NAS descubrió arquitecturas como NASNet y EfficientNet.",
          de: "NAS (2017+) nutzte Reinforcement Learning, evolutionäre Algorithmen oder gradientenbasierte Methoden um automatisch optimale Netzwerkarchitekturen zu suchen. Obwohl initial rechenintensiv, entdeckte NAS Architekturen wie NASNet und EfficientNet.",
          nl: "NAS (2017+) gebruikte reinforcement learning, evolutionaire algoritmen of gradiënt-gebaseerde methoden om automatisch te zoeken naar optimale netwerk architecturen. Hoewel initieel computationeel duur, ontdekte NAS architecturen zoals NASNet en EfficientNet."
        }
      },
      {
        question: {
          en: "What was the legacy of the 2010s deep learning revolution?",
          es: "¿Cuál fue el legado de la revolución del aprendizaje profundo de los 2010?",
          de: "Was war das Vermächtnis der Deep Learning-Revolution der 2010er?",
          nl: "Wat was de erfenis van de deep learning revolutie van de jaren 2010?"
        },
        options: [
          { en: "It established neural networks as dominant AI approach, enabling modern applications from GPT to self-driving cars", es: "Estableció redes neuronales como enfoque dominante de IA, permitiendo aplicaciones modernas desde GPT hasta autos autónomos", de: "Es etablierte neuronale Netzwerke als dominanten KI-Ansatz und ermöglichte moderne Anwendungen von GPT bis selbstfahrende Autos", nl: "Het vestigde neurale netwerken als dominante AI benadering, wat moderne toepassingen mogelijk maakte van GPT tot zelfrijdende auto's" },
          { en: "It only improved image quality", es: "Solo mejoró la calidad de imagen", de: "Es verbesserte nur Bildqualität", nl: "Het verbeterde alleen beeldkwaliteit" },
          { en: "It created social media", es: "Creó redes sociales", de: "Es schuf soziale Medien", nl: "Het creëerde sociale media" },
          { en: "It invented the internet", es: "Inventó internet", de: "Es erfand das Internet", nl: "Het vond het internet uit" }
        ],
        correct: 0,
        explanation: {
          en: "The 2010s deep learning revolution fundamentally transformed AI from niche academic pursuit to transformative technology. It established foundations for modern systems: computer vision (object detection, face recognition), NLP (language models, translation), speech (Alexa, Siri), gaming (AlphaGo), autonomous vehicles, medical diagnosis, and generative AI. Deep learning became the dominant paradigm for AI research and applications.",
          es: "La revolución del aprendizaje profundo de los 2010 transformó fundamentalmente IA de búsqueda académica de nicho a tecnología transformadora. Estableció fundamentos para sistemas modernos: visión por computadora, NLP, voz, juegos, vehículos autónomos, diagnóstico médico e IA generativa.",
          de: "Die Deep Learning-Revolution der 2010er transformierte KI fundamental von akademischer Nische zu transformativer Technologie. Sie etablierte Grundlagen für moderne Systeme: Computer Vision, NLP, Sprache, Gaming, autonome Fahrzeuge, medizinische Diagnose und generative KI.",
          nl: "De deep learning revolutie van de jaren 2010 transformeerde AI fundamenteel van niche academische bezigheid tot transformatieve technologie. Het vestigde fundamenten voor moderne systemen: computer vision, NLP, spraak, gaming, autonome voertuigen, medische diagnose en generatieve AI."
        }
      }
    ]
  };

  if (typeof module !== 'undefined' && module.exports) {
    module.exports = level7;
  } else if (typeof window !== 'undefined') {
    window.level7 = level7;
  }
})();